{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('../data/iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species\n",
       "0             5.1          3.5           1.4          0.2     setosa\n",
       "1             4.9          3.0           1.4          0.2     setosa\n",
       "2             4.7          3.2           1.3          0.2     setosa\n",
       "3             4.6          3.1           1.5          0.2     setosa\n",
       "4             5.0          3.6           1.4          0.2     setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "145           6.7          3.0           5.2          2.3  virginica\n",
       "146           6.3          2.5           5.0          1.9  virginica\n",
       "147           6.5          3.0           5.2          2.0  virginica\n",
       "148           6.2          3.4           5.4          2.3  virginica\n",
       "149           5.9          3.0           5.1          1.8  virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.drop('species', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "0             5.1          3.5           1.4          0.2\n",
       "1             4.9          3.0           1.4          0.2\n",
       "2             4.7          3.2           1.3          0.2\n",
       "3             4.6          3.1           1.5          0.2\n",
       "4             5.0          3.6           1.4          0.2\n",
       "..            ...          ...           ...          ...\n",
       "145           6.7          3.0           5.2          2.3\n",
       "146           6.3          2.5           5.0          1.9\n",
       "147           6.5          3.0           5.2          2.0\n",
       "148           6.2          3.4           5.4          2.3\n",
       "149           5.9          3.0           5.1          1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         setosa\n",
       "1         setosa\n",
       "2         setosa\n",
       "3         setosa\n",
       "4         setosa\n",
       "         ...    \n",
       "145    virginica\n",
       "146    virginica\n",
       "147    virginica\n",
       "148    virginica\n",
       "149    virginica\n",
       "Name: species, Length: 150, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.61111111, 0.41666667, 0.81355932, 0.875     ],\n",
       "       [0.33333333, 0.20833333, 0.50847458, 0.5       ],\n",
       "       [0.61111111, 0.41666667, 0.76271186, 0.70833333],\n",
       "       [0.41666667, 0.29166667, 0.49152542, 0.45833333],\n",
       "       [0.69444444, 0.41666667, 0.76271186, 0.83333333],\n",
       "       [0.38888889, 0.33333333, 0.59322034, 0.5       ],\n",
       "       [0.66666667, 0.45833333, 0.62711864, 0.58333333],\n",
       "       [0.44444444, 0.41666667, 0.54237288, 0.58333333],\n",
       "       [0.36111111, 0.29166667, 0.54237288, 0.5       ],\n",
       "       [0.94444444, 0.41666667, 0.86440678, 0.91666667],\n",
       "       [0.22222222, 0.70833333, 0.08474576, 0.125     ],\n",
       "       [0.08333333, 0.66666667, 0.        , 0.04166667],\n",
       "       [0.11111111, 0.5       , 0.10169492, 0.04166667],\n",
       "       [0.66666667, 0.41666667, 0.6779661 , 0.66666667],\n",
       "       [0.36111111, 0.41666667, 0.59322034, 0.58333333],\n",
       "       [0.        , 0.41666667, 0.01694915, 0.        ],\n",
       "       [0.77777778, 0.41666667, 0.83050847, 0.83333333],\n",
       "       [0.41666667, 0.29166667, 0.52542373, 0.375     ],\n",
       "       [0.16666667, 0.45833333, 0.08474576, 0.04166667],\n",
       "       [0.22222222, 0.20833333, 0.33898305, 0.41666667],\n",
       "       [0.36111111, 0.20833333, 0.49152542, 0.41666667],\n",
       "       [0.22222222, 0.54166667, 0.11864407, 0.16666667],\n",
       "       [0.41666667, 0.29166667, 0.69491525, 0.75      ],\n",
       "       [0.19444444, 0.66666667, 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.16666667, 0.38983051, 0.375     ],\n",
       "       [0.66666667, 0.20833333, 0.81355932, 0.70833333],\n",
       "       [0.41666667, 0.25      , 0.50847458, 0.45833333],\n",
       "       [0.16666667, 0.66666667, 0.06779661, 0.        ],\n",
       "       [0.22222222, 0.58333333, 0.08474576, 0.04166667],\n",
       "       [0.5       , 0.41666667, 0.61016949, 0.54166667],\n",
       "       [0.08333333, 0.58333333, 0.06779661, 0.08333333],\n",
       "       [0.58333333, 0.5       , 0.59322034, 0.58333333],\n",
       "       [0.94444444, 0.25      , 1.        , 0.91666667],\n",
       "       [0.55555556, 0.58333333, 0.77966102, 0.95833333],\n",
       "       [0.30555556, 0.41666667, 0.59322034, 0.58333333],\n",
       "       [0.41666667, 0.83333333, 0.03389831, 0.04166667],\n",
       "       [0.47222222, 0.375     , 0.59322034, 0.58333333],\n",
       "       [0.08333333, 0.45833333, 0.08474576, 0.04166667],\n",
       "       [0.41666667, 0.29166667, 0.69491525, 0.75      ],\n",
       "       [0.72222222, 0.5       , 0.79661017, 0.91666667],\n",
       "       [0.47222222, 0.58333333, 0.59322034, 0.625     ],\n",
       "       [0.52777778, 0.58333333, 0.74576271, 0.91666667],\n",
       "       [0.63888889, 0.375     , 0.61016949, 0.5       ],\n",
       "       [0.55555556, 0.54166667, 0.84745763, 1.        ],\n",
       "       [0.11111111, 0.5       , 0.05084746, 0.04166667],\n",
       "       [0.13888889, 0.41666667, 0.06779661, 0.08333333],\n",
       "       [0.16666667, 0.45833333, 0.08474576, 0.        ],\n",
       "       [0.61111111, 0.33333333, 0.61016949, 0.58333333],\n",
       "       [0.08333333, 0.5       , 0.06779661, 0.04166667],\n",
       "       [0.22222222, 0.75      , 0.10169492, 0.04166667],\n",
       "       [0.19444444, 0.58333333, 0.10169492, 0.125     ],\n",
       "       [0.86111111, 0.33333333, 0.86440678, 0.75      ],\n",
       "       [0.25      , 0.625     , 0.08474576, 0.04166667],\n",
       "       [0.30555556, 0.58333333, 0.11864407, 0.04166667],\n",
       "       [0.47222222, 0.41666667, 0.6440678 , 0.70833333],\n",
       "       [0.52777778, 0.33333333, 0.6440678 , 0.70833333],\n",
       "       [0.13888889, 0.45833333, 0.10169492, 0.04166667],\n",
       "       [0.19444444, 0.5       , 0.03389831, 0.04166667],\n",
       "       [0.80555556, 0.5       , 0.84745763, 0.70833333],\n",
       "       [0.80555556, 0.66666667, 0.86440678, 1.        ],\n",
       "       [0.38888889, 0.20833333, 0.6779661 , 0.79166667],\n",
       "       [0.13888889, 0.58333333, 0.15254237, 0.04166667],\n",
       "       [0.38888889, 0.25      , 0.42372881, 0.375     ],\n",
       "       [0.69444444, 0.5       , 0.83050847, 0.91666667],\n",
       "       [0.22222222, 0.625     , 0.06779661, 0.08333333],\n",
       "       [0.13888889, 0.41666667, 0.06779661, 0.        ],\n",
       "       [0.47222222, 0.08333333, 0.6779661 , 0.58333333],\n",
       "       [0.58333333, 0.33333333, 0.77966102, 0.83333333],\n",
       "       [0.38888889, 1.        , 0.08474576, 0.125     ],\n",
       "       [0.5       , 0.33333333, 0.50847458, 0.5       ],\n",
       "       [0.38888889, 0.75      , 0.11864407, 0.08333333],\n",
       "       [0.16666667, 0.20833333, 0.59322034, 0.66666667],\n",
       "       [0.94444444, 0.75      , 0.96610169, 0.875     ],\n",
       "       [0.02777778, 0.41666667, 0.05084746, 0.04166667],\n",
       "       [0.55555556, 0.375     , 0.77966102, 0.70833333],\n",
       "       [0.55555556, 0.54166667, 0.62711864, 0.625     ],\n",
       "       [0.72222222, 0.45833333, 0.66101695, 0.58333333],\n",
       "       [0.66666667, 0.54166667, 0.79661017, 0.83333333],\n",
       "       [0.19444444, 0.58333333, 0.08474576, 0.04166667],\n",
       "       [0.72222222, 0.45833333, 0.74576271, 0.83333333],\n",
       "       [0.25      , 0.58333333, 0.06779661, 0.04166667],\n",
       "       [0.38888889, 0.33333333, 0.52542373, 0.5       ],\n",
       "       [0.55555556, 0.33333333, 0.69491525, 0.58333333],\n",
       "       [0.33333333, 0.625     , 0.05084746, 0.04166667],\n",
       "       [0.47222222, 0.08333333, 0.50847458, 0.375     ],\n",
       "       [0.02777778, 0.375     , 0.06779661, 0.04166667],\n",
       "       [0.66666667, 0.45833333, 0.77966102, 0.95833333],\n",
       "       [0.5       , 0.33333333, 0.62711864, 0.45833333],\n",
       "       [0.91666667, 0.41666667, 0.94915254, 0.83333333],\n",
       "       [0.22222222, 0.625     , 0.06779661, 0.04166667],\n",
       "       [0.66666667, 0.54166667, 0.79661017, 1.        ],\n",
       "       [0.83333333, 0.375     , 0.89830508, 0.70833333],\n",
       "       [0.44444444, 0.41666667, 0.69491525, 0.70833333],\n",
       "       [0.69444444, 0.33333333, 0.6440678 , 0.54166667],\n",
       "       [0.30555556, 0.70833333, 0.08474576, 0.04166667],\n",
       "       [0.22222222, 0.75      , 0.08474576, 0.08333333],\n",
       "       [0.36111111, 0.33333333, 0.66101695, 0.79166667],\n",
       "       [0.55555556, 0.20833333, 0.66101695, 0.58333333],\n",
       "       [0.22222222, 0.75      , 0.15254237, 0.125     ],\n",
       "       [0.25      , 0.29166667, 0.49152542, 0.54166667],\n",
       "       [1.        , 0.75      , 0.91525424, 0.79166667],\n",
       "       [0.58333333, 0.5       , 0.72881356, 0.91666667],\n",
       "       [0.58333333, 0.29166667, 0.72881356, 0.75      ],\n",
       "       [0.47222222, 0.29166667, 0.69491525, 0.625     ],\n",
       "       [0.19444444, 0.54166667, 0.06779661, 0.04166667],\n",
       "       [0.72222222, 0.45833333, 0.69491525, 0.91666667],\n",
       "       [0.30555556, 0.79166667, 0.11864407, 0.125     ],\n",
       "       [0.61111111, 0.5       , 0.69491525, 0.79166667],\n",
       "       [0.19444444, 0.        , 0.42372881, 0.375     ],\n",
       "       [0.66666667, 0.41666667, 0.71186441, 0.91666667],\n",
       "       [0.58333333, 0.33333333, 0.77966102, 0.875     ],\n",
       "       [0.19444444, 0.625     , 0.05084746, 0.08333333],\n",
       "       [0.58333333, 0.45833333, 0.76271186, 0.70833333],\n",
       "       [0.63888889, 0.41666667, 0.57627119, 0.54166667],\n",
       "       [0.55555556, 0.125     , 0.57627119, 0.5       ],\n",
       "       [0.5       , 0.375     , 0.62711864, 0.54166667],\n",
       "       [0.44444444, 0.5       , 0.6440678 , 0.70833333],\n",
       "       [0.33333333, 0.16666667, 0.45762712, 0.375     ],\n",
       "       [0.13888889, 0.58333333, 0.10169492, 0.04166667],\n",
       "       [0.38888889, 0.41666667, 0.54237288, 0.45833333]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=4,activation='relu',input_shape=[4,]))\n",
    "\n",
    "# Last layer for multi-class classification of 3 species\n",
    "model.add(Dense(units=3,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 15        \n",
      "=================================================================\n",
      "Total params: 35\n",
      "Trainable params: 35\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/300\n",
      "120/120 [==============================] - 0s 3ms/sample - loss: 1.0729 - accuracy: 0.3500 - val_loss: 1.0756 - val_accuracy: 0.3667\n",
      "Epoch 2/300\n",
      "120/120 [==============================] - 0s 98us/sample - loss: 1.0705 - accuracy: 0.3417 - val_loss: 1.0733 - val_accuracy: 0.3333\n",
      "Epoch 3/300\n",
      "120/120 [==============================] - 0s 126us/sample - loss: 1.0679 - accuracy: 0.3667 - val_loss: 1.0709 - val_accuracy: 0.3667\n",
      "Epoch 4/300\n",
      "120/120 [==============================] - 0s 141us/sample - loss: 1.0655 - accuracy: 0.3917 - val_loss: 1.0685 - val_accuracy: 0.3667\n",
      "Epoch 5/300\n",
      "120/120 [==============================] - 0s 141us/sample - loss: 1.0630 - accuracy: 0.4083 - val_loss: 1.0660 - val_accuracy: 0.3667\n",
      "Epoch 6/300\n",
      "120/120 [==============================] - 0s 149us/sample - loss: 1.0605 - accuracy: 0.4333 - val_loss: 1.0634 - val_accuracy: 0.4000\n",
      "Epoch 7/300\n",
      "120/120 [==============================] - 0s 131us/sample - loss: 1.0579 - accuracy: 0.5083 - val_loss: 1.0610 - val_accuracy: 0.4000\n",
      "Epoch 8/300\n",
      "120/120 [==============================] - 0s 138us/sample - loss: 1.0552 - accuracy: 0.5500 - val_loss: 1.0584 - val_accuracy: 0.4667\n",
      "Epoch 9/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 1.0525 - accuracy: 0.5833 - val_loss: 1.0560 - val_accuracy: 0.4667\n",
      "Epoch 10/300\n",
      "120/120 [==============================] - 0s 159us/sample - loss: 1.0498 - accuracy: 0.5917 - val_loss: 1.0535 - val_accuracy: 0.5333\n",
      "Epoch 11/300\n",
      "120/120 [==============================] - 0s 151us/sample - loss: 1.0470 - accuracy: 0.5917 - val_loss: 1.0510 - val_accuracy: 0.5000\n",
      "Epoch 12/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 1.0442 - accuracy: 0.6083 - val_loss: 1.0488 - val_accuracy: 0.5000\n",
      "Epoch 13/300\n",
      "120/120 [==============================] - 0s 141us/sample - loss: 1.0415 - accuracy: 0.6083 - val_loss: 1.0466 - val_accuracy: 0.5000\n",
      "Epoch 14/300\n",
      "120/120 [==============================] - 0s 123us/sample - loss: 1.0386 - accuracy: 0.6167 - val_loss: 1.0444 - val_accuracy: 0.4667\n",
      "Epoch 15/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 1.0358 - accuracy: 0.6083 - val_loss: 1.0422 - val_accuracy: 0.4667\n",
      "Epoch 16/300\n",
      "120/120 [==============================] - 0s 146us/sample - loss: 1.0329 - accuracy: 0.6167 - val_loss: 1.0400 - val_accuracy: 0.4667\n",
      "Epoch 17/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 1.0300 - accuracy: 0.6167 - val_loss: 1.0377 - val_accuracy: 0.4667\n",
      "Epoch 18/300\n",
      "120/120 [==============================] - 0s 146us/sample - loss: 1.0271 - accuracy: 0.6000 - val_loss: 1.0354 - val_accuracy: 0.4333\n",
      "Epoch 19/300\n",
      "120/120 [==============================] - 0s 178us/sample - loss: 1.0242 - accuracy: 0.5917 - val_loss: 1.0332 - val_accuracy: 0.4333\n",
      "Epoch 20/300\n",
      "120/120 [==============================] - 0s 141us/sample - loss: 1.0215 - accuracy: 0.5833 - val_loss: 1.0310 - val_accuracy: 0.4333\n",
      "Epoch 21/300\n",
      "120/120 [==============================] - 0s 143us/sample - loss: 1.0185 - accuracy: 0.5833 - val_loss: 1.0287 - val_accuracy: 0.4333\n",
      "Epoch 22/300\n",
      "120/120 [==============================] - 0s 137us/sample - loss: 1.0153 - accuracy: 0.5833 - val_loss: 1.0263 - val_accuracy: 0.4333\n",
      "Epoch 23/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 1.0120 - accuracy: 0.5833 - val_loss: 1.0236 - val_accuracy: 0.5000\n",
      "Epoch 24/300\n",
      "120/120 [==============================] - 0s 137us/sample - loss: 1.0082 - accuracy: 0.5917 - val_loss: 1.0206 - val_accuracy: 0.5333\n",
      "Epoch 25/300\n",
      "120/120 [==============================] - 0s 132us/sample - loss: 1.0047 - accuracy: 0.5833 - val_loss: 1.0178 - val_accuracy: 0.5333\n",
      "Epoch 26/300\n",
      "120/120 [==============================] - 0s 157us/sample - loss: 1.0007 - accuracy: 0.5833 - val_loss: 1.0141 - val_accuracy: 0.5333\n",
      "Epoch 27/300\n",
      "120/120 [==============================] - 0s 139us/sample - loss: 0.9969 - accuracy: 0.5833 - val_loss: 1.0105 - val_accuracy: 0.5333\n",
      "Epoch 28/300\n",
      "120/120 [==============================] - 0s 140us/sample - loss: 0.9930 - accuracy: 0.5917 - val_loss: 1.0070 - val_accuracy: 0.5333\n",
      "Epoch 29/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.9891 - accuracy: 0.6083 - val_loss: 1.0035 - val_accuracy: 0.5333\n",
      "Epoch 30/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.9852 - accuracy: 0.6333 - val_loss: 1.0001 - val_accuracy: 0.5667\n",
      "Epoch 31/300\n",
      "120/120 [==============================] - 0s 132us/sample - loss: 0.9812 - accuracy: 0.6333 - val_loss: 0.9968 - val_accuracy: 0.5667\n",
      "Epoch 32/300\n",
      "120/120 [==============================] - 0s 135us/sample - loss: 0.9773 - accuracy: 0.6417 - val_loss: 0.9931 - val_accuracy: 0.5667\n",
      "Epoch 33/300\n",
      "120/120 [==============================] - 0s 141us/sample - loss: 0.9731 - accuracy: 0.6500 - val_loss: 0.9894 - val_accuracy: 0.5667\n",
      "Epoch 34/300\n",
      "120/120 [==============================] - 0s 141us/sample - loss: 0.9689 - accuracy: 0.6500 - val_loss: 0.9859 - val_accuracy: 0.5667\n",
      "Epoch 35/300\n",
      "120/120 [==============================] - 0s 151us/sample - loss: 0.9649 - accuracy: 0.6500 - val_loss: 0.9824 - val_accuracy: 0.5667\n",
      "Epoch 36/300\n",
      "120/120 [==============================] - 0s 155us/sample - loss: 0.9608 - accuracy: 0.6500 - val_loss: 0.9786 - val_accuracy: 0.5667\n",
      "Epoch 37/300\n",
      "120/120 [==============================] - 0s 153us/sample - loss: 0.9566 - accuracy: 0.6500 - val_loss: 0.9749 - val_accuracy: 0.6000\n",
      "Epoch 38/300\n",
      "120/120 [==============================] - 0s 140us/sample - loss: 0.9523 - accuracy: 0.6500 - val_loss: 0.9711 - val_accuracy: 0.6000\n",
      "Epoch 39/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.9482 - accuracy: 0.6667 - val_loss: 0.9671 - val_accuracy: 0.6000\n",
      "Epoch 40/300\n",
      "120/120 [==============================] - 0s 155us/sample - loss: 0.9441 - accuracy: 0.6667 - val_loss: 0.9634 - val_accuracy: 0.6000\n",
      "Epoch 41/300\n",
      "120/120 [==============================] - 0s 141us/sample - loss: 0.9397 - accuracy: 0.6750 - val_loss: 0.9596 - val_accuracy: 0.6000\n",
      "Epoch 42/300\n",
      "120/120 [==============================] - 0s 163us/sample - loss: 0.9355 - accuracy: 0.6750 - val_loss: 0.9559 - val_accuracy: 0.6000\n",
      "Epoch 43/300\n",
      "120/120 [==============================] - 0s 143us/sample - loss: 0.9315 - accuracy: 0.6750 - val_loss: 0.9522 - val_accuracy: 0.6000\n",
      "Epoch 44/300\n",
      "120/120 [==============================] - 0s 122us/sample - loss: 0.9272 - accuracy: 0.6750 - val_loss: 0.9482 - val_accuracy: 0.6000\n",
      "Epoch 45/300\n",
      "120/120 [==============================] - 0s 121us/sample - loss: 0.9230 - accuracy: 0.6750 - val_loss: 0.9444 - val_accuracy: 0.6000\n",
      "Epoch 46/300\n",
      "120/120 [==============================] - 0s 201us/sample - loss: 0.9188 - accuracy: 0.6583 - val_loss: 0.9403 - val_accuracy: 0.6000\n",
      "Epoch 47/300\n",
      "120/120 [==============================] - 0s 120us/sample - loss: 0.9148 - accuracy: 0.6500 - val_loss: 0.9365 - val_accuracy: 0.6000\n",
      "Epoch 48/300\n",
      "120/120 [==============================] - 0s 124us/sample - loss: 0.9102 - accuracy: 0.6500 - val_loss: 0.9324 - val_accuracy: 0.6000\n",
      "Epoch 49/300\n",
      "120/120 [==============================] - 0s 147us/sample - loss: 0.9062 - accuracy: 0.6500 - val_loss: 0.9284 - val_accuracy: 0.6000\n",
      "Epoch 50/300\n",
      "120/120 [==============================] - 0s 123us/sample - loss: 0.9019 - accuracy: 0.6500 - val_loss: 0.9244 - val_accuracy: 0.6000\n",
      "Epoch 51/300\n",
      "120/120 [==============================] - 0s 144us/sample - loss: 0.8974 - accuracy: 0.6500 - val_loss: 0.9203 - val_accuracy: 0.5667\n",
      "Epoch 52/300\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.9090 - accuracy: 0.62 - 0s 144us/sample - loss: 0.8932 - accuracy: 0.6500 - val_loss: 0.9162 - val_accuracy: 0.5667\n",
      "Epoch 53/300\n",
      "120/120 [==============================] - 0s 213us/sample - loss: 0.8891 - accuracy: 0.6500 - val_loss: 0.9122 - val_accuracy: 0.5667\n",
      "Epoch 54/300\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.8849 - accuracy: 0.6500 - val_loss: 0.9082 - val_accuracy: 0.5667\n",
      "Epoch 55/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.8806 - accuracy: 0.6500 - val_loss: 0.9039 - val_accuracy: 0.5667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/300\n",
      "120/120 [==============================] - 0s 189us/sample - loss: 0.8762 - accuracy: 0.6500 - val_loss: 0.9000 - val_accuracy: 0.5667\n",
      "Epoch 57/300\n",
      "120/120 [==============================] - 0s 168us/sample - loss: 0.8720 - accuracy: 0.6500 - val_loss: 0.8959 - val_accuracy: 0.5667\n",
      "Epoch 58/300\n",
      "120/120 [==============================] - 0s 148us/sample - loss: 0.8676 - accuracy: 0.6583 - val_loss: 0.8919 - val_accuracy: 0.5667\n",
      "Epoch 59/300\n",
      "120/120 [==============================] - 0s 148us/sample - loss: 0.8637 - accuracy: 0.6583 - val_loss: 0.8877 - val_accuracy: 0.5667\n",
      "Epoch 60/300\n",
      "120/120 [==============================] - 0s 156us/sample - loss: 0.8592 - accuracy: 0.6583 - val_loss: 0.8837 - val_accuracy: 0.5667\n",
      "Epoch 61/300\n",
      "120/120 [==============================] - 0s 147us/sample - loss: 0.8549 - accuracy: 0.6583 - val_loss: 0.8795 - val_accuracy: 0.5667\n",
      "Epoch 62/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.8506 - accuracy: 0.6583 - val_loss: 0.8757 - val_accuracy: 0.5667\n",
      "Epoch 63/300\n",
      "120/120 [==============================] - 0s 140us/sample - loss: 0.8466 - accuracy: 0.6583 - val_loss: 0.8718 - val_accuracy: 0.5667\n",
      "Epoch 64/300\n",
      "120/120 [==============================] - 0s 139us/sample - loss: 0.8422 - accuracy: 0.6667 - val_loss: 0.8677 - val_accuracy: 0.6000\n",
      "Epoch 65/300\n",
      "120/120 [==============================] - 0s 159us/sample - loss: 0.8379 - accuracy: 0.6833 - val_loss: 0.8637 - val_accuracy: 0.6000\n",
      "Epoch 66/300\n",
      "120/120 [==============================] - 0s 113us/sample - loss: 0.8337 - accuracy: 0.6833 - val_loss: 0.8596 - val_accuracy: 0.6000\n",
      "Epoch 67/300\n",
      "120/120 [==============================] - 0s 107us/sample - loss: 0.8294 - accuracy: 0.6750 - val_loss: 0.8555 - val_accuracy: 0.6000\n",
      "Epoch 68/300\n",
      "120/120 [==============================] - 0s 103us/sample - loss: 0.8253 - accuracy: 0.6750 - val_loss: 0.8515 - val_accuracy: 0.6000\n",
      "Epoch 69/300\n",
      "120/120 [==============================] - 0s 121us/sample - loss: 0.8211 - accuracy: 0.6750 - val_loss: 0.8475 - val_accuracy: 0.6000\n",
      "Epoch 70/300\n",
      "120/120 [==============================] - 0s 119us/sample - loss: 0.8169 - accuracy: 0.6750 - val_loss: 0.8433 - val_accuracy: 0.6000\n",
      "Epoch 71/300\n",
      "120/120 [==============================] - 0s 124us/sample - loss: 0.8128 - accuracy: 0.6750 - val_loss: 0.8393 - val_accuracy: 0.6000\n",
      "Epoch 72/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.8087 - accuracy: 0.6750 - val_loss: 0.8354 - val_accuracy: 0.6000\n",
      "Epoch 73/300\n",
      "120/120 [==============================] - 0s 116us/sample - loss: 0.8044 - accuracy: 0.6750 - val_loss: 0.8316 - val_accuracy: 0.6000\n",
      "Epoch 74/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.8002 - accuracy: 0.6750 - val_loss: 0.8277 - val_accuracy: 0.6000\n",
      "Epoch 75/300\n",
      "120/120 [==============================] - 0s 110us/sample - loss: 0.7961 - accuracy: 0.6750 - val_loss: 0.8238 - val_accuracy: 0.6000\n",
      "Epoch 76/300\n",
      "120/120 [==============================] - 0s 114us/sample - loss: 0.7920 - accuracy: 0.6750 - val_loss: 0.8198 - val_accuracy: 0.6000\n",
      "Epoch 77/300\n",
      "120/120 [==============================] - 0s 114us/sample - loss: 0.7879 - accuracy: 0.6750 - val_loss: 0.8159 - val_accuracy: 0.6000\n",
      "Epoch 78/300\n",
      "120/120 [==============================] - 0s 144us/sample - loss: 0.7839 - accuracy: 0.6750 - val_loss: 0.8120 - val_accuracy: 0.6000\n",
      "Epoch 79/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.7797 - accuracy: 0.6833 - val_loss: 0.8082 - val_accuracy: 0.6000\n",
      "Epoch 80/300\n",
      "120/120 [==============================] - 0s 105us/sample - loss: 0.7759 - accuracy: 0.6833 - val_loss: 0.8046 - val_accuracy: 0.6000\n",
      "Epoch 81/300\n",
      "120/120 [==============================] - 0s 121us/sample - loss: 0.7717 - accuracy: 0.6833 - val_loss: 0.8006 - val_accuracy: 0.6000\n",
      "Epoch 82/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.7677 - accuracy: 0.6833 - val_loss: 0.7967 - val_accuracy: 0.6000\n",
      "Epoch 83/300\n",
      "120/120 [==============================] - 0s 107us/sample - loss: 0.7639 - accuracy: 0.6833 - val_loss: 0.7931 - val_accuracy: 0.6000\n",
      "Epoch 84/300\n",
      "120/120 [==============================] - 0s 110us/sample - loss: 0.7598 - accuracy: 0.6833 - val_loss: 0.7895 - val_accuracy: 0.6000\n",
      "Epoch 85/300\n",
      "120/120 [==============================] - 0s 115us/sample - loss: 0.7559 - accuracy: 0.6833 - val_loss: 0.7858 - val_accuracy: 0.6000\n",
      "Epoch 86/300\n",
      "120/120 [==============================] - 0s 99us/sample - loss: 0.7521 - accuracy: 0.6833 - val_loss: 0.7820 - val_accuracy: 0.6000\n",
      "Epoch 87/300\n",
      "120/120 [==============================] - 0s 114us/sample - loss: 0.7482 - accuracy: 0.6833 - val_loss: 0.7786 - val_accuracy: 0.6000\n",
      "Epoch 88/300\n",
      "120/120 [==============================] - 0s 124us/sample - loss: 0.7444 - accuracy: 0.6833 - val_loss: 0.7748 - val_accuracy: 0.6000\n",
      "Epoch 89/300\n",
      "120/120 [==============================] - 0s 113us/sample - loss: 0.7405 - accuracy: 0.6833 - val_loss: 0.7713 - val_accuracy: 0.6000\n",
      "Epoch 90/300\n",
      "120/120 [==============================] - 0s 110us/sample - loss: 0.7368 - accuracy: 0.6833 - val_loss: 0.7678 - val_accuracy: 0.6000\n",
      "Epoch 91/300\n",
      "120/120 [==============================] - 0s 113us/sample - loss: 0.7330 - accuracy: 0.6833 - val_loss: 0.7643 - val_accuracy: 0.6000\n",
      "Epoch 92/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.7294 - accuracy: 0.6833 - val_loss: 0.7606 - val_accuracy: 0.6000\n",
      "Epoch 93/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 0.7257 - accuracy: 0.6833 - val_loss: 0.7573 - val_accuracy: 0.6000\n",
      "Epoch 94/300\n",
      "120/120 [==============================] - 0s 99us/sample - loss: 0.7222 - accuracy: 0.6833 - val_loss: 0.7540 - val_accuracy: 0.6000\n",
      "Epoch 95/300\n",
      "120/120 [==============================] - 0s 114us/sample - loss: 0.7184 - accuracy: 0.6833 - val_loss: 0.7506 - val_accuracy: 0.6000\n",
      "Epoch 96/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.7149 - accuracy: 0.6833 - val_loss: 0.7473 - val_accuracy: 0.6000\n",
      "Epoch 97/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.7113 - accuracy: 0.6833 - val_loss: 0.7441 - val_accuracy: 0.6000\n",
      "Epoch 98/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.7078 - accuracy: 0.6833 - val_loss: 0.7408 - val_accuracy: 0.6000\n",
      "Epoch 99/300\n",
      "120/120 [==============================] - 0s 112us/sample - loss: 0.7044 - accuracy: 0.6833 - val_loss: 0.7375 - val_accuracy: 0.6000\n",
      "Epoch 100/300\n",
      "120/120 [==============================] - 0s 105us/sample - loss: 0.7009 - accuracy: 0.6833 - val_loss: 0.7342 - val_accuracy: 0.6000\n",
      "Epoch 101/300\n",
      "120/120 [==============================] - 0s 105us/sample - loss: 0.6975 - accuracy: 0.6833 - val_loss: 0.7310 - val_accuracy: 0.6000\n",
      "Epoch 102/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 0.6941 - accuracy: 0.6833 - val_loss: 0.7277 - val_accuracy: 0.6000\n",
      "Epoch 103/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.6907 - accuracy: 0.6833 - val_loss: 0.7247 - val_accuracy: 0.6000\n",
      "Epoch 104/300\n",
      "120/120 [==============================] - 0s 110us/sample - loss: 0.6875 - accuracy: 0.6833 - val_loss: 0.7216 - val_accuracy: 0.6000\n",
      "Epoch 105/300\n",
      "120/120 [==============================] - 0s 113us/sample - loss: 0.6842 - accuracy: 0.6833 - val_loss: 0.7183 - val_accuracy: 0.6000\n",
      "Epoch 106/300\n",
      "120/120 [==============================] - 0s 160us/sample - loss: 0.6810 - accuracy: 0.6833 - val_loss: 0.7151 - val_accuracy: 0.6000\n",
      "Epoch 107/300\n",
      "120/120 [==============================] - 0s 143us/sample - loss: 0.6777 - accuracy: 0.6833 - val_loss: 0.7123 - val_accuracy: 0.6000\n",
      "Epoch 108/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.6745 - accuracy: 0.6833 - val_loss: 0.7092 - val_accuracy: 0.6000\n",
      "Epoch 109/300\n",
      "120/120 [==============================] - 0s 123us/sample - loss: 0.6714 - accuracy: 0.6833 - val_loss: 0.7063 - val_accuracy: 0.6000\n",
      "Epoch 110/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 0.6683 - accuracy: 0.6833 - val_loss: 0.7035 - val_accuracy: 0.6000\n",
      "Epoch 111/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 108us/sample - loss: 0.6652 - accuracy: 0.6833 - val_loss: 0.7007 - val_accuracy: 0.6000\n",
      "Epoch 112/300\n",
      "120/120 [==============================] - 0s 115us/sample - loss: 0.6621 - accuracy: 0.6833 - val_loss: 0.6979 - val_accuracy: 0.6000\n",
      "Epoch 113/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.6590 - accuracy: 0.6833 - val_loss: 0.6952 - val_accuracy: 0.6000\n",
      "Epoch 114/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.6561 - accuracy: 0.6833 - val_loss: 0.6923 - val_accuracy: 0.6000\n",
      "Epoch 115/300\n",
      "120/120 [==============================] - 0s 115us/sample - loss: 0.6531 - accuracy: 0.6833 - val_loss: 0.6898 - val_accuracy: 0.6000\n",
      "Epoch 116/300\n",
      "120/120 [==============================] - 0s 112us/sample - loss: 0.6502 - accuracy: 0.6833 - val_loss: 0.6869 - val_accuracy: 0.6000\n",
      "Epoch 117/300\n",
      "120/120 [==============================] - 0s 116us/sample - loss: 0.6474 - accuracy: 0.6833 - val_loss: 0.6843 - val_accuracy: 0.6000\n",
      "Epoch 118/300\n",
      "120/120 [==============================] - 0s 105us/sample - loss: 0.6444 - accuracy: 0.6833 - val_loss: 0.6816 - val_accuracy: 0.6000\n",
      "Epoch 119/300\n",
      "120/120 [==============================] - 0s 99us/sample - loss: 0.6417 - accuracy: 0.6833 - val_loss: 0.6792 - val_accuracy: 0.6000\n",
      "Epoch 120/300\n",
      "120/120 [==============================] - 0s 103us/sample - loss: 0.6388 - accuracy: 0.6833 - val_loss: 0.6766 - val_accuracy: 0.6000\n",
      "Epoch 121/300\n",
      "120/120 [==============================] - 0s 99us/sample - loss: 0.6361 - accuracy: 0.6833 - val_loss: 0.6741 - val_accuracy: 0.6000\n",
      "Epoch 122/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.6333 - accuracy: 0.6833 - val_loss: 0.6713 - val_accuracy: 0.6000\n",
      "Epoch 123/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 0.6306 - accuracy: 0.6833 - val_loss: 0.6688 - val_accuracy: 0.6000\n",
      "Epoch 124/300\n",
      "120/120 [==============================] - 0s 115us/sample - loss: 0.6279 - accuracy: 0.6833 - val_loss: 0.6661 - val_accuracy: 0.6000\n",
      "Epoch 125/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.6253 - accuracy: 0.6833 - val_loss: 0.6637 - val_accuracy: 0.6000\n",
      "Epoch 126/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.6226 - accuracy: 0.6833 - val_loss: 0.6612 - val_accuracy: 0.6000\n",
      "Epoch 127/300\n",
      "120/120 [==============================] - 0s 103us/sample - loss: 0.6201 - accuracy: 0.6833 - val_loss: 0.6588 - val_accuracy: 0.6000\n",
      "Epoch 128/300\n",
      "120/120 [==============================] - 0s 119us/sample - loss: 0.6175 - accuracy: 0.6833 - val_loss: 0.6561 - val_accuracy: 0.6000\n",
      "Epoch 129/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 0.6149 - accuracy: 0.6833 - val_loss: 0.6536 - val_accuracy: 0.6000\n",
      "Epoch 130/300\n",
      "120/120 [==============================] - 0s 114us/sample - loss: 0.6125 - accuracy: 0.6833 - val_loss: 0.6513 - val_accuracy: 0.6000\n",
      "Epoch 131/300\n",
      "120/120 [==============================] - 0s 115us/sample - loss: 0.6099 - accuracy: 0.6833 - val_loss: 0.6489 - val_accuracy: 0.6000\n",
      "Epoch 132/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.6074 - accuracy: 0.6833 - val_loss: 0.6466 - val_accuracy: 0.6000\n",
      "Epoch 133/300\n",
      "120/120 [==============================] - 0s 123us/sample - loss: 0.6050 - accuracy: 0.6833 - val_loss: 0.6443 - val_accuracy: 0.6000\n",
      "Epoch 134/300\n",
      "120/120 [==============================] - 0s 131us/sample - loss: 0.6026 - accuracy: 0.6833 - val_loss: 0.6421 - val_accuracy: 0.6000\n",
      "Epoch 135/300\n",
      "120/120 [==============================] - 0s 137us/sample - loss: 0.6002 - accuracy: 0.6833 - val_loss: 0.6400 - val_accuracy: 0.6000\n",
      "Epoch 136/300\n",
      "120/120 [==============================] - 0s 147us/sample - loss: 0.5979 - accuracy: 0.6833 - val_loss: 0.6377 - val_accuracy: 0.6000\n",
      "Epoch 137/300\n",
      "120/120 [==============================] - 0s 143us/sample - loss: 0.5956 - accuracy: 0.6833 - val_loss: 0.6357 - val_accuracy: 0.6000\n",
      "Epoch 138/300\n",
      "120/120 [==============================] - 0s 146us/sample - loss: 0.5933 - accuracy: 0.6833 - val_loss: 0.6337 - val_accuracy: 0.6000\n",
      "Epoch 139/300\n",
      "120/120 [==============================] - 0s 140us/sample - loss: 0.5911 - accuracy: 0.6833 - val_loss: 0.6316 - val_accuracy: 0.6000\n",
      "Epoch 140/300\n",
      "120/120 [==============================] - 0s 152us/sample - loss: 0.5888 - accuracy: 0.6833 - val_loss: 0.6295 - val_accuracy: 0.6000\n",
      "Epoch 141/300\n",
      "120/120 [==============================] - 0s 140us/sample - loss: 0.5866 - accuracy: 0.6833 - val_loss: 0.6276 - val_accuracy: 0.6000\n",
      "Epoch 142/300\n",
      "120/120 [==============================] - 0s 148us/sample - loss: 0.5845 - accuracy: 0.6833 - val_loss: 0.6255 - val_accuracy: 0.6000\n",
      "Epoch 143/300\n",
      "120/120 [==============================] - 0s 157us/sample - loss: 0.5823 - accuracy: 0.6833 - val_loss: 0.6237 - val_accuracy: 0.6000\n",
      "Epoch 144/300\n",
      "120/120 [==============================] - 0s 146us/sample - loss: 0.5802 - accuracy: 0.6833 - val_loss: 0.6219 - val_accuracy: 0.6000\n",
      "Epoch 145/300\n",
      "120/120 [==============================] - 0s 186us/sample - loss: 0.5780 - accuracy: 0.6833 - val_loss: 0.6199 - val_accuracy: 0.6000\n",
      "Epoch 146/300\n",
      "120/120 [==============================] - 0s 232us/sample - loss: 0.5760 - accuracy: 0.6833 - val_loss: 0.6180 - val_accuracy: 0.6000\n",
      "Epoch 147/300\n",
      "120/120 [==============================] - 0s 148us/sample - loss: 0.5738 - accuracy: 0.6833 - val_loss: 0.6163 - val_accuracy: 0.6000\n",
      "Epoch 148/300\n",
      "120/120 [==============================] - 0s 130us/sample - loss: 0.5718 - accuracy: 0.6833 - val_loss: 0.6145 - val_accuracy: 0.6000\n",
      "Epoch 149/300\n",
      "120/120 [==============================] - 0s 118us/sample - loss: 0.5698 - accuracy: 0.6833 - val_loss: 0.6127 - val_accuracy: 0.6000\n",
      "Epoch 150/300\n",
      "120/120 [==============================] - 0s 116us/sample - loss: 0.5679 - accuracy: 0.6833 - val_loss: 0.6108 - val_accuracy: 0.6000\n",
      "Epoch 151/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 0.5659 - accuracy: 0.6833 - val_loss: 0.6092 - val_accuracy: 0.6000\n",
      "Epoch 152/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.5641 - accuracy: 0.6833 - val_loss: 0.6076 - val_accuracy: 0.6000\n",
      "Epoch 153/300\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 0.5623 - accuracy: 0.6833 - val_loss: 0.6059 - val_accuracy: 0.6000\n",
      "Epoch 154/300\n",
      "120/120 [==============================] - 0s 99us/sample - loss: 0.5604 - accuracy: 0.6833 - val_loss: 0.6042 - val_accuracy: 0.6000\n",
      "Epoch 155/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 0.5586 - accuracy: 0.6833 - val_loss: 0.6025 - val_accuracy: 0.6000\n",
      "Epoch 156/300\n",
      "120/120 [==============================] - 0s 105us/sample - loss: 0.5569 - accuracy: 0.6833 - val_loss: 0.6008 - val_accuracy: 0.6000\n",
      "Epoch 157/300\n",
      "120/120 [==============================] - 0s 106us/sample - loss: 0.5551 - accuracy: 0.6833 - val_loss: 0.5992 - val_accuracy: 0.6000\n",
      "Epoch 158/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.5534 - accuracy: 0.6833 - val_loss: 0.5976 - val_accuracy: 0.6000\n",
      "Epoch 159/300\n",
      "120/120 [==============================] - 0s 99us/sample - loss: 0.5518 - accuracy: 0.6833 - val_loss: 0.5961 - val_accuracy: 0.6000\n",
      "Epoch 160/300\n",
      "120/120 [==============================] - 0s 99us/sample - loss: 0.5500 - accuracy: 0.6833 - val_loss: 0.5944 - val_accuracy: 0.6000\n",
      "Epoch 161/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.5484 - accuracy: 0.6833 - val_loss: 0.5927 - val_accuracy: 0.6000\n",
      "Epoch 162/300\n",
      "120/120 [==============================] - 0s 107us/sample - loss: 0.5468 - accuracy: 0.6833 - val_loss: 0.5912 - val_accuracy: 0.6000\n",
      "Epoch 163/300\n",
      "120/120 [==============================] - 0s 102us/sample - loss: 0.5452 - accuracy: 0.6833 - val_loss: 0.5899 - val_accuracy: 0.6000\n",
      "Epoch 164/300\n",
      "120/120 [==============================] - 0s 101us/sample - loss: 0.5436 - accuracy: 0.6833 - val_loss: 0.5882 - val_accuracy: 0.6000\n",
      "Epoch 165/300\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 0.5419 - accuracy: 0.6833 - val_loss: 0.5867 - val_accuracy: 0.6000\n",
      "Epoch 166/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 113us/sample - loss: 0.5404 - accuracy: 0.6833 - val_loss: 0.5853 - val_accuracy: 0.6000\n",
      "Epoch 167/300\n",
      "120/120 [==============================] - 0s 110us/sample - loss: 0.5388 - accuracy: 0.6833 - val_loss: 0.5838 - val_accuracy: 0.6000\n",
      "Epoch 168/300\n",
      "120/120 [==============================] - 0s 105us/sample - loss: 0.5373 - accuracy: 0.6833 - val_loss: 0.5824 - val_accuracy: 0.6000\n",
      "Epoch 169/300\n",
      "120/120 [==============================] - 0s 106us/sample - loss: 0.5359 - accuracy: 0.6833 - val_loss: 0.5808 - val_accuracy: 0.6000\n",
      "Epoch 170/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.5343 - accuracy: 0.6833 - val_loss: 0.5794 - val_accuracy: 0.6000\n",
      "Epoch 171/300\n",
      "120/120 [==============================] - 0s 107us/sample - loss: 0.5329 - accuracy: 0.6833 - val_loss: 0.5781 - val_accuracy: 0.6000\n",
      "Epoch 172/300\n",
      "120/120 [==============================] - 0s 102us/sample - loss: 0.5315 - accuracy: 0.6833 - val_loss: 0.5768 - val_accuracy: 0.6000\n",
      "Epoch 173/300\n",
      "120/120 [==============================] - 0s 101us/sample - loss: 0.5300 - accuracy: 0.6833 - val_loss: 0.5755 - val_accuracy: 0.6000\n",
      "Epoch 174/300\n",
      "120/120 [==============================] - 0s 107us/sample - loss: 0.5286 - accuracy: 0.6833 - val_loss: 0.5742 - val_accuracy: 0.6000\n",
      "Epoch 175/300\n",
      "120/120 [==============================] - 0s 97us/sample - loss: 0.5272 - accuracy: 0.6833 - val_loss: 0.5727 - val_accuracy: 0.6000\n",
      "Epoch 176/300\n",
      "120/120 [==============================] - 0s 102us/sample - loss: 0.5259 - accuracy: 0.6833 - val_loss: 0.5713 - val_accuracy: 0.6000\n",
      "Epoch 177/300\n",
      "120/120 [==============================] - 0s 97us/sample - loss: 0.5245 - accuracy: 0.6833 - val_loss: 0.5699 - val_accuracy: 0.6000\n",
      "Epoch 178/300\n",
      "120/120 [==============================] - 0s 106us/sample - loss: 0.5232 - accuracy: 0.6833 - val_loss: 0.5687 - val_accuracy: 0.6000\n",
      "Epoch 179/300\n",
      "120/120 [==============================] - 0s 132us/sample - loss: 0.5219 - accuracy: 0.6833 - val_loss: 0.5673 - val_accuracy: 0.6000\n",
      "Epoch 180/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.5206 - accuracy: 0.6833 - val_loss: 0.5661 - val_accuracy: 0.6000\n",
      "Epoch 181/300\n",
      "120/120 [==============================] - 0s 122us/sample - loss: 0.5193 - accuracy: 0.6833 - val_loss: 0.5648 - val_accuracy: 0.6000\n",
      "Epoch 182/300\n",
      "120/120 [==============================] - 0s 115us/sample - loss: 0.5180 - accuracy: 0.6833 - val_loss: 0.5633 - val_accuracy: 0.6000\n",
      "Epoch 183/300\n",
      "120/120 [==============================] - 0s 112us/sample - loss: 0.5168 - accuracy: 0.6833 - val_loss: 0.5621 - val_accuracy: 0.6000\n",
      "Epoch 184/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.5156 - accuracy: 0.6833 - val_loss: 0.5608 - val_accuracy: 0.6000\n",
      "Epoch 185/300\n",
      "120/120 [==============================] - 0s 210us/sample - loss: 0.5144 - accuracy: 0.6833 - val_loss: 0.5597 - val_accuracy: 0.6000\n",
      "Epoch 186/300\n",
      "120/120 [==============================] - 0s 170us/sample - loss: 0.5131 - accuracy: 0.6833 - val_loss: 0.5584 - val_accuracy: 0.6000\n",
      "Epoch 187/300\n",
      "120/120 [==============================] - 0s 210us/sample - loss: 0.5120 - accuracy: 0.6833 - val_loss: 0.5571 - val_accuracy: 0.6000\n",
      "Epoch 188/300\n",
      "120/120 [==============================] - 0s 201us/sample - loss: 0.5108 - accuracy: 0.6833 - val_loss: 0.5558 - val_accuracy: 0.6000\n",
      "Epoch 189/300\n",
      "120/120 [==============================] - 0s 229us/sample - loss: 0.5097 - accuracy: 0.6833 - val_loss: 0.5548 - val_accuracy: 0.6000\n",
      "Epoch 190/300\n",
      "120/120 [==============================] - 0s 243us/sample - loss: 0.5086 - accuracy: 0.6833 - val_loss: 0.5535 - val_accuracy: 0.6000\n",
      "Epoch 191/300\n",
      "120/120 [==============================] - 0s 300us/sample - loss: 0.5075 - accuracy: 0.6833 - val_loss: 0.5522 - val_accuracy: 0.6000\n",
      "Epoch 192/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.5063 - accuracy: 0.6833 - val_loss: 0.5512 - val_accuracy: 0.6000\n",
      "Epoch 193/300\n",
      "120/120 [==============================] - 0s 211us/sample - loss: 0.5052 - accuracy: 0.6833 - val_loss: 0.5502 - val_accuracy: 0.6000\n",
      "Epoch 194/300\n",
      "120/120 [==============================] - 0s 239us/sample - loss: 0.5042 - accuracy: 0.6833 - val_loss: 0.5491 - val_accuracy: 0.6000\n",
      "Epoch 195/300\n",
      "120/120 [==============================] - 0s 186us/sample - loss: 0.5031 - accuracy: 0.6833 - val_loss: 0.5481 - val_accuracy: 0.6000\n",
      "Epoch 196/300\n",
      "120/120 [==============================] - 0s 210us/sample - loss: 0.5021 - accuracy: 0.6833 - val_loss: 0.5472 - val_accuracy: 0.6000\n",
      "Epoch 197/300\n",
      "120/120 [==============================] - 0s 179us/sample - loss: 0.5010 - accuracy: 0.6833 - val_loss: 0.5462 - val_accuracy: 0.6000\n",
      "Epoch 198/300\n",
      "120/120 [==============================] - 0s 194us/sample - loss: 0.5001 - accuracy: 0.6833 - val_loss: 0.5454 - val_accuracy: 0.6000\n",
      "Epoch 199/300\n",
      "120/120 [==============================] - 0s 190us/sample - loss: 0.4990 - accuracy: 0.6833 - val_loss: 0.5443 - val_accuracy: 0.6000\n",
      "Epoch 200/300\n",
      "120/120 [==============================] - 0s 185us/sample - loss: 0.4980 - accuracy: 0.6833 - val_loss: 0.5433 - val_accuracy: 0.6000\n",
      "Epoch 201/300\n",
      "120/120 [==============================] - 0s 205us/sample - loss: 0.4970 - accuracy: 0.6833 - val_loss: 0.5423 - val_accuracy: 0.6000\n",
      "Epoch 202/300\n",
      "120/120 [==============================] - 0s 193us/sample - loss: 0.4960 - accuracy: 0.6833 - val_loss: 0.5414 - val_accuracy: 0.6000\n",
      "Epoch 203/300\n",
      "120/120 [==============================] - 0s 198us/sample - loss: 0.4950 - accuracy: 0.6833 - val_loss: 0.5402 - val_accuracy: 0.6000\n",
      "Epoch 204/300\n",
      "120/120 [==============================] - 0s 207us/sample - loss: 0.4941 - accuracy: 0.6833 - val_loss: 0.5391 - val_accuracy: 0.6000\n",
      "Epoch 205/300\n",
      "120/120 [==============================] - 0s 193us/sample - loss: 0.4931 - accuracy: 0.6833 - val_loss: 0.5381 - val_accuracy: 0.6000\n",
      "Epoch 206/300\n",
      "120/120 [==============================] - 0s 199us/sample - loss: 0.4922 - accuracy: 0.6833 - val_loss: 0.5371 - val_accuracy: 0.6000\n",
      "Epoch 207/300\n",
      "120/120 [==============================] - 0s 191us/sample - loss: 0.4913 - accuracy: 0.6833 - val_loss: 0.5362 - val_accuracy: 0.6000\n",
      "Epoch 208/300\n",
      "120/120 [==============================] - 0s 206us/sample - loss: 0.4904 - accuracy: 0.6833 - val_loss: 0.5352 - val_accuracy: 0.6000\n",
      "Epoch 209/300\n",
      "120/120 [==============================] - 0s 209us/sample - loss: 0.4894 - accuracy: 0.6833 - val_loss: 0.5343 - val_accuracy: 0.6000\n",
      "Epoch 210/300\n",
      "120/120 [==============================] - 0s 195us/sample - loss: 0.4885 - accuracy: 0.6833 - val_loss: 0.5332 - val_accuracy: 0.6000\n",
      "Epoch 211/300\n",
      "120/120 [==============================] - 0s 185us/sample - loss: 0.4877 - accuracy: 0.6833 - val_loss: 0.5320 - val_accuracy: 0.6000\n",
      "Epoch 212/300\n",
      "120/120 [==============================] - 0s 186us/sample - loss: 0.4868 - accuracy: 0.6833 - val_loss: 0.5311 - val_accuracy: 0.6000\n",
      "Epoch 213/300\n",
      "120/120 [==============================] - 0s 186us/sample - loss: 0.4859 - accuracy: 0.6833 - val_loss: 0.5300 - val_accuracy: 0.6000\n",
      "Epoch 214/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.4850 - accuracy: 0.6833 - val_loss: 0.5290 - val_accuracy: 0.6000\n",
      "Epoch 215/300\n",
      "120/120 [==============================] - 0s 185us/sample - loss: 0.4842 - accuracy: 0.6833 - val_loss: 0.5281 - val_accuracy: 0.6000\n",
      "Epoch 216/300\n",
      "120/120 [==============================] - 0s 179us/sample - loss: 0.4833 - accuracy: 0.6833 - val_loss: 0.5271 - val_accuracy: 0.6000\n",
      "Epoch 217/300\n",
      "120/120 [==============================] - 0s 170us/sample - loss: 0.4825 - accuracy: 0.6833 - val_loss: 0.5261 - val_accuracy: 0.6000\n",
      "Epoch 218/300\n",
      "120/120 [==============================] - 0s 185us/sample - loss: 0.4817 - accuracy: 0.6917 - val_loss: 0.5252 - val_accuracy: 0.6000\n",
      "Epoch 219/300\n",
      "120/120 [==============================] - 0s 213us/sample - loss: 0.4808 - accuracy: 0.6917 - val_loss: 0.5242 - val_accuracy: 0.6000\n",
      "Epoch 220/300\n",
      "120/120 [==============================] - 0s 196us/sample - loss: 0.4800 - accuracy: 0.6917 - val_loss: 0.5232 - val_accuracy: 0.6000\n",
      "Epoch 221/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 233us/sample - loss: 0.4792 - accuracy: 0.6917 - val_loss: 0.5224 - val_accuracy: 0.6000\n",
      "Epoch 222/300\n",
      "120/120 [==============================] - 0s 210us/sample - loss: 0.4785 - accuracy: 0.7000 - val_loss: 0.5214 - val_accuracy: 0.6333\n",
      "Epoch 223/300\n",
      "120/120 [==============================] - 0s 191us/sample - loss: 0.4777 - accuracy: 0.7000 - val_loss: 0.5206 - val_accuracy: 0.6333\n",
      "Epoch 224/300\n",
      "120/120 [==============================] - 0s 184us/sample - loss: 0.4769 - accuracy: 0.7000 - val_loss: 0.5197 - val_accuracy: 0.6333\n",
      "Epoch 225/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.4761 - accuracy: 0.7000 - val_loss: 0.5188 - val_accuracy: 0.6333\n",
      "Epoch 226/300\n",
      "120/120 [==============================] - 0s 156us/sample - loss: 0.4753 - accuracy: 0.7000 - val_loss: 0.5180 - val_accuracy: 0.6333\n",
      "Epoch 227/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.4746 - accuracy: 0.7000 - val_loss: 0.5171 - val_accuracy: 0.6333\n",
      "Epoch 228/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.4738 - accuracy: 0.7000 - val_loss: 0.5164 - val_accuracy: 0.6333\n",
      "Epoch 229/300\n",
      "120/120 [==============================] - 0s 137us/sample - loss: 0.4730 - accuracy: 0.7000 - val_loss: 0.5157 - val_accuracy: 0.6333\n",
      "Epoch 230/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.4723 - accuracy: 0.7000 - val_loss: 0.5151 - val_accuracy: 0.6333\n",
      "Epoch 231/300\n",
      "120/120 [==============================] - 0s 119us/sample - loss: 0.4716 - accuracy: 0.7000 - val_loss: 0.5143 - val_accuracy: 0.6333\n",
      "Epoch 232/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.4709 - accuracy: 0.7000 - val_loss: 0.5137 - val_accuracy: 0.6333\n",
      "Epoch 233/300\n",
      "120/120 [==============================] - 0s 119us/sample - loss: 0.4701 - accuracy: 0.7000 - val_loss: 0.5128 - val_accuracy: 0.6333\n",
      "Epoch 234/300\n",
      "120/120 [==============================] - 0s 116us/sample - loss: 0.4694 - accuracy: 0.7000 - val_loss: 0.5119 - val_accuracy: 0.6333\n",
      "Epoch 235/300\n",
      "120/120 [==============================] - 0s 137us/sample - loss: 0.4687 - accuracy: 0.7000 - val_loss: 0.5111 - val_accuracy: 0.6333\n",
      "Epoch 236/300\n",
      "120/120 [==============================] - 0s 130us/sample - loss: 0.4680 - accuracy: 0.7000 - val_loss: 0.5103 - val_accuracy: 0.6333\n",
      "Epoch 237/300\n",
      "120/120 [==============================] - 0s 126us/sample - loss: 0.4673 - accuracy: 0.7083 - val_loss: 0.5096 - val_accuracy: 0.6333\n",
      "Epoch 238/300\n",
      "120/120 [==============================] - 0s 124us/sample - loss: 0.4666 - accuracy: 0.7083 - val_loss: 0.5089 - val_accuracy: 0.6333\n",
      "Epoch 239/300\n",
      "120/120 [==============================] - 0s 132us/sample - loss: 0.4659 - accuracy: 0.7167 - val_loss: 0.5082 - val_accuracy: 0.6333\n",
      "Epoch 240/300\n",
      "120/120 [==============================] - 0s 122us/sample - loss: 0.4653 - accuracy: 0.7167 - val_loss: 0.5074 - val_accuracy: 0.6333\n",
      "Epoch 241/300\n",
      "120/120 [==============================] - 0s 149us/sample - loss: 0.4646 - accuracy: 0.7167 - val_loss: 0.5067 - val_accuracy: 0.6333\n",
      "Epoch 242/300\n",
      "120/120 [==============================] - 0s 140us/sample - loss: 0.4639 - accuracy: 0.7167 - val_loss: 0.5059 - val_accuracy: 0.6333\n",
      "Epoch 243/300\n",
      "120/120 [==============================] - 0s 151us/sample - loss: 0.4633 - accuracy: 0.7167 - val_loss: 0.5052 - val_accuracy: 0.6333\n",
      "Epoch 244/300\n",
      "120/120 [==============================] - 0s 160us/sample - loss: 0.4626 - accuracy: 0.7167 - val_loss: 0.5046 - val_accuracy: 0.6333\n",
      "Epoch 245/300\n",
      "120/120 [==============================] - 0s 151us/sample - loss: 0.4620 - accuracy: 0.7167 - val_loss: 0.5039 - val_accuracy: 0.6333\n",
      "Epoch 246/300\n",
      "120/120 [==============================] - 0s 136us/sample - loss: 0.4614 - accuracy: 0.7167 - val_loss: 0.5031 - val_accuracy: 0.6333\n",
      "Epoch 247/300\n",
      "120/120 [==============================] - 0s 148us/sample - loss: 0.4607 - accuracy: 0.7167 - val_loss: 0.5025 - val_accuracy: 0.6333\n",
      "Epoch 248/300\n",
      "120/120 [==============================] - 0s 130us/sample - loss: 0.4601 - accuracy: 0.7167 - val_loss: 0.5018 - val_accuracy: 0.6333\n",
      "Epoch 249/300\n",
      "120/120 [==============================] - 0s 110us/sample - loss: 0.4594 - accuracy: 0.7167 - val_loss: 0.5012 - val_accuracy: 0.6333\n",
      "Epoch 250/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.4588 - accuracy: 0.7167 - val_loss: 0.5005 - val_accuracy: 0.6333\n",
      "Epoch 251/300\n",
      "120/120 [==============================] - 0s 116us/sample - loss: 0.4582 - accuracy: 0.7167 - val_loss: 0.4997 - val_accuracy: 0.6333\n",
      "Epoch 252/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.4576 - accuracy: 0.7167 - val_loss: 0.4990 - val_accuracy: 0.6333\n",
      "Epoch 253/300\n",
      "120/120 [==============================] - 0s 114us/sample - loss: 0.4570 - accuracy: 0.7167 - val_loss: 0.4982 - val_accuracy: 0.6333\n",
      "Epoch 254/300\n",
      "120/120 [==============================] - 0s 121us/sample - loss: 0.4564 - accuracy: 0.7167 - val_loss: 0.4977 - val_accuracy: 0.6333\n",
      "Epoch 255/300\n",
      "120/120 [==============================] - 0s 130us/sample - loss: 0.4558 - accuracy: 0.7167 - val_loss: 0.4971 - val_accuracy: 0.6333\n",
      "Epoch 256/300\n",
      "120/120 [==============================] - 0s 132us/sample - loss: 0.4552 - accuracy: 0.7167 - val_loss: 0.4966 - val_accuracy: 0.6333\n",
      "Epoch 257/300\n",
      "120/120 [==============================] - 0s 147us/sample - loss: 0.4546 - accuracy: 0.7167 - val_loss: 0.4958 - val_accuracy: 0.6333\n",
      "Epoch 258/300\n",
      "120/120 [==============================] - 0s 156us/sample - loss: 0.4540 - accuracy: 0.7167 - val_loss: 0.4952 - val_accuracy: 0.6333\n",
      "Epoch 259/300\n",
      "120/120 [==============================] - 0s 151us/sample - loss: 0.4534 - accuracy: 0.7167 - val_loss: 0.4944 - val_accuracy: 0.6333\n",
      "Epoch 260/300\n",
      "120/120 [==============================] - 0s 160us/sample - loss: 0.4529 - accuracy: 0.7250 - val_loss: 0.4936 - val_accuracy: 0.6333\n",
      "Epoch 261/300\n",
      "120/120 [==============================] - 0s 152us/sample - loss: 0.4523 - accuracy: 0.7333 - val_loss: 0.4930 - val_accuracy: 0.6333\n",
      "Epoch 262/300\n",
      "120/120 [==============================] - 0s 168us/sample - loss: 0.4517 - accuracy: 0.7333 - val_loss: 0.4924 - val_accuracy: 0.6333\n",
      "Epoch 263/300\n",
      "120/120 [==============================] - 0s 155us/sample - loss: 0.4512 - accuracy: 0.7333 - val_loss: 0.4918 - val_accuracy: 0.6333\n",
      "Epoch 264/300\n",
      "120/120 [==============================] - 0s 219us/sample - loss: 0.4506 - accuracy: 0.7333 - val_loss: 0.4912 - val_accuracy: 0.6333\n",
      "Epoch 265/300\n",
      "120/120 [==============================] - 0s 179us/sample - loss: 0.4501 - accuracy: 0.7333 - val_loss: 0.4904 - val_accuracy: 0.6333\n",
      "Epoch 266/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.4495 - accuracy: 0.7333 - val_loss: 0.4897 - val_accuracy: 0.6333\n",
      "Epoch 267/300\n",
      "120/120 [==============================] - 0s 202us/sample - loss: 0.4490 - accuracy: 0.7333 - val_loss: 0.4890 - val_accuracy: 0.6333\n",
      "Epoch 268/300\n",
      "120/120 [==============================] - 0s 193us/sample - loss: 0.4484 - accuracy: 0.7333 - val_loss: 0.4885 - val_accuracy: 0.6333\n",
      "Epoch 269/300\n",
      "120/120 [==============================] - 0s 194us/sample - loss: 0.4479 - accuracy: 0.7333 - val_loss: 0.4879 - val_accuracy: 0.6333\n",
      "Epoch 270/300\n",
      "120/120 [==============================] - 0s 180us/sample - loss: 0.4474 - accuracy: 0.7250 - val_loss: 0.4871 - val_accuracy: 0.6333\n",
      "Epoch 271/300\n",
      "120/120 [==============================] - 0s 219us/sample - loss: 0.4468 - accuracy: 0.7250 - val_loss: 0.4866 - val_accuracy: 0.6333\n",
      "Epoch 272/300\n",
      "120/120 [==============================] - 0s 160us/sample - loss: 0.4463 - accuracy: 0.7250 - val_loss: 0.4862 - val_accuracy: 0.6333\n",
      "Epoch 273/300\n",
      "120/120 [==============================] - 0s 157us/sample - loss: 0.4458 - accuracy: 0.7250 - val_loss: 0.4856 - val_accuracy: 0.6333\n",
      "Epoch 274/300\n",
      "120/120 [==============================] - 0s 145us/sample - loss: 0.4453 - accuracy: 0.7250 - val_loss: 0.4852 - val_accuracy: 0.6333\n",
      "Epoch 275/300\n",
      "120/120 [==============================] - 0s 145us/sample - loss: 0.4447 - accuracy: 0.7250 - val_loss: 0.4846 - val_accuracy: 0.6333\n",
      "Epoch 276/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 148us/sample - loss: 0.4442 - accuracy: 0.7250 - val_loss: 0.4839 - val_accuracy: 0.6333\n",
      "Epoch 277/300\n",
      "120/120 [==============================] - 0s 160us/sample - loss: 0.4437 - accuracy: 0.7250 - val_loss: 0.4832 - val_accuracy: 0.6333\n",
      "Epoch 278/300\n",
      "120/120 [==============================] - 0s 128us/sample - loss: 0.4433 - accuracy: 0.7250 - val_loss: 0.4824 - val_accuracy: 0.7000\n",
      "Epoch 279/300\n",
      "120/120 [==============================] - 0s 146us/sample - loss: 0.4427 - accuracy: 0.7250 - val_loss: 0.4819 - val_accuracy: 0.7000\n",
      "Epoch 280/300\n",
      "120/120 [==============================] - 0s 110us/sample - loss: 0.4422 - accuracy: 0.7250 - val_loss: 0.4812 - val_accuracy: 0.7333\n",
      "Epoch 281/300\n",
      "120/120 [==============================] - 0s 116us/sample - loss: 0.4417 - accuracy: 0.7250 - val_loss: 0.4808 - val_accuracy: 0.7333\n",
      "Epoch 282/300\n",
      "120/120 [==============================] - 0s 112us/sample - loss: 0.4413 - accuracy: 0.7250 - val_loss: 0.4802 - val_accuracy: 0.7333\n",
      "Epoch 283/300\n",
      "120/120 [==============================] - 0s 120us/sample - loss: 0.4408 - accuracy: 0.7250 - val_loss: 0.4796 - val_accuracy: 0.7333\n",
      "Epoch 284/300\n",
      "120/120 [==============================] - 0s 121us/sample - loss: 0.4403 - accuracy: 0.7250 - val_loss: 0.4790 - val_accuracy: 0.7333\n",
      "Epoch 285/300\n",
      "120/120 [==============================] - 0s 119us/sample - loss: 0.4398 - accuracy: 0.7250 - val_loss: 0.4783 - val_accuracy: 0.7333\n",
      "Epoch 286/300\n",
      "120/120 [==============================] - 0s 113us/sample - loss: 0.4393 - accuracy: 0.7417 - val_loss: 0.4777 - val_accuracy: 0.7333\n",
      "Epoch 287/300\n",
      "120/120 [==============================] - 0s 121us/sample - loss: 0.4388 - accuracy: 0.7417 - val_loss: 0.4771 - val_accuracy: 0.7333\n",
      "Epoch 288/300\n",
      "120/120 [==============================] - 0s 120us/sample - loss: 0.4384 - accuracy: 0.7500 - val_loss: 0.4766 - val_accuracy: 0.7333\n",
      "Epoch 289/300\n",
      "120/120 [==============================] - 0s 112us/sample - loss: 0.4379 - accuracy: 0.7500 - val_loss: 0.4759 - val_accuracy: 0.7667\n",
      "Epoch 290/300\n",
      "120/120 [==============================] - 0s 120us/sample - loss: 0.4374 - accuracy: 0.7583 - val_loss: 0.4753 - val_accuracy: 0.7667\n",
      "Epoch 291/300\n",
      "120/120 [==============================] - 0s 116us/sample - loss: 0.4370 - accuracy: 0.7583 - val_loss: 0.4746 - val_accuracy: 0.7667\n",
      "Epoch 292/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.4365 - accuracy: 0.7583 - val_loss: 0.4740 - val_accuracy: 0.7667\n",
      "Epoch 293/300\n",
      "120/120 [==============================] - 0s 135us/sample - loss: 0.4360 - accuracy: 0.7583 - val_loss: 0.4736 - val_accuracy: 0.8000\n",
      "Epoch 294/300\n",
      "120/120 [==============================] - 0s 129us/sample - loss: 0.4356 - accuracy: 0.7583 - val_loss: 0.4730 - val_accuracy: 0.8000\n",
      "Epoch 295/300\n",
      "120/120 [==============================] - 0s 135us/sample - loss: 0.4351 - accuracy: 0.7583 - val_loss: 0.4726 - val_accuracy: 0.8000\n",
      "Epoch 296/300\n",
      "120/120 [==============================] - 0s 122us/sample - loss: 0.4347 - accuracy: 0.7583 - val_loss: 0.4720 - val_accuracy: 0.8000\n",
      "Epoch 297/300\n",
      "120/120 [==============================] - 0s 116us/sample - loss: 0.4342 - accuracy: 0.7583 - val_loss: 0.4713 - val_accuracy: 0.8000\n",
      "Epoch 298/300\n",
      "120/120 [==============================] - 0s 162us/sample - loss: 0.4337 - accuracy: 0.7667 - val_loss: 0.4708 - val_accuracy: 0.8000\n",
      "Epoch 299/300\n",
      "120/120 [==============================] - 0s 139us/sample - loss: 0.4332 - accuracy: 0.7667 - val_loss: 0.4703 - val_accuracy: 0.8000\n",
      "Epoch 300/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.4328 - accuracy: 0.7667 - val_loss: 0.4700 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14945d940>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_train, y=y_train, epochs=300,\n",
    "         validation_data=(scaled_test, y_test), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x149569e48>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['loss', 'val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1495f9780>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['accuracy', 'val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4700333774089813, 0.8]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(scaled_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = len(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_complete = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=4,activation='relu',input_shape=[4,]))\n",
    "\n",
    "# Last layer for multi-class classification of 3 species\n",
    "model.add(Dense(units=3,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150 samples\n",
      "Epoch 1/300\n",
      "150/150 [==============================] - 0s 2ms/sample - loss: 0.9636 - accuracy: 0.6800\n",
      "Epoch 2/300\n",
      "150/150 [==============================] - 0s 58us/sample - loss: 0.9589 - accuracy: 0.6800\n",
      "Epoch 3/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.9544 - accuracy: 0.6867\n",
      "Epoch 4/300\n",
      "150/150 [==============================] - 0s 68us/sample - loss: 0.9498 - accuracy: 0.6800\n",
      "Epoch 5/300\n",
      "150/150 [==============================] - 0s 77us/sample - loss: 0.9452 - accuracy: 0.6800\n",
      "Epoch 6/300\n",
      "150/150 [==============================] - 0s 97us/sample - loss: 0.9408 - accuracy: 0.6800\n",
      "Epoch 7/300\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.9361 - accuracy: 0.6733\n",
      "Epoch 8/300\n",
      "150/150 [==============================] - 0s 88us/sample - loss: 0.9317 - accuracy: 0.6600\n",
      "Epoch 9/300\n",
      "150/150 [==============================] - 0s 85us/sample - loss: 0.9271 - accuracy: 0.6733\n",
      "Epoch 10/300\n",
      "150/150 [==============================] - 0s 85us/sample - loss: 0.9225 - accuracy: 0.6733\n",
      "Epoch 11/300\n",
      "150/150 [==============================] - 0s 99us/sample - loss: 0.9179 - accuracy: 0.6733\n",
      "Epoch 12/300\n",
      "150/150 [==============================] - 0s 82us/sample - loss: 0.9133 - accuracy: 0.6733\n",
      "Epoch 13/300\n",
      "150/150 [==============================] - 0s 149us/sample - loss: 0.9088 - accuracy: 0.6733\n",
      "Epoch 14/300\n",
      "150/150 [==============================] - 0s 103us/sample - loss: 0.9042 - accuracy: 0.6800\n",
      "Epoch 15/300\n",
      "150/150 [==============================] - 0s 85us/sample - loss: 0.8996 - accuracy: 0.6800\n",
      "Epoch 16/300\n",
      "150/150 [==============================] - 0s 72us/sample - loss: 0.8949 - accuracy: 0.6800\n",
      "Epoch 17/300\n",
      "150/150 [==============================] - 0s 84us/sample - loss: 0.8902 - accuracy: 0.6800\n",
      "Epoch 18/300\n",
      "150/150 [==============================] - 0s 68us/sample - loss: 0.8855 - accuracy: 0.6800\n",
      "Epoch 19/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.8807 - accuracy: 0.6800\n",
      "Epoch 20/300\n",
      "150/150 [==============================] - 0s 82us/sample - loss: 0.8758 - accuracy: 0.6800\n",
      "Epoch 21/300\n",
      "150/150 [==============================] - 0s 109us/sample - loss: 0.8710 - accuracy: 0.6800\n",
      "Epoch 22/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.8660 - accuracy: 0.6800\n",
      "Epoch 23/300\n",
      "150/150 [==============================] - 0s 114us/sample - loss: 0.8610 - accuracy: 0.6867\n",
      "Epoch 24/300\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.8559 - accuracy: 0.7067\n",
      "Epoch 25/300\n",
      "150/150 [==============================] - 0s 111us/sample - loss: 0.8508 - accuracy: 0.7067\n",
      "Epoch 26/300\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.8452 - accuracy: 0.75 - 0s 116us/sample - loss: 0.8456 - accuracy: 0.7067\n",
      "Epoch 27/300\n",
      "150/150 [==============================] - 0s 132us/sample - loss: 0.8403 - accuracy: 0.7000\n",
      "Epoch 28/300\n",
      "150/150 [==============================] - 0s 116us/sample - loss: 0.8349 - accuracy: 0.7000\n",
      "Epoch 29/300\n",
      "150/150 [==============================] - 0s 104us/sample - loss: 0.8292 - accuracy: 0.7267\n",
      "Epoch 30/300\n",
      "150/150 [==============================] - 0s 108us/sample - loss: 0.8235 - accuracy: 0.7267\n",
      "Epoch 31/300\n",
      "150/150 [==============================] - 0s 144us/sample - loss: 0.8174 - accuracy: 0.7267\n",
      "Epoch 32/300\n",
      "150/150 [==============================] - 0s 104us/sample - loss: 0.8110 - accuracy: 0.7600\n",
      "Epoch 33/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.8050 - accuracy: 0.7600\n",
      "Epoch 34/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.7985 - accuracy: 0.7600\n",
      "Epoch 35/300\n",
      "150/150 [==============================] - 0s 92us/sample - loss: 0.7924 - accuracy: 0.7600\n",
      "Epoch 36/300\n",
      "150/150 [==============================] - 0s 70us/sample - loss: 0.7860 - accuracy: 0.7667\n",
      "Epoch 37/300\n",
      "150/150 [==============================] - 0s 84us/sample - loss: 0.7798 - accuracy: 0.7733\n",
      "Epoch 38/300\n",
      "150/150 [==============================] - 0s 65us/sample - loss: 0.7733 - accuracy: 0.7733\n",
      "Epoch 39/300\n",
      "150/150 [==============================] - 0s 70us/sample - loss: 0.7673 - accuracy: 0.7800\n",
      "Epoch 40/300\n",
      "150/150 [==============================] - 0s 104us/sample - loss: 0.7608 - accuracy: 0.7867\n",
      "Epoch 41/300\n",
      "150/150 [==============================] - 0s 89us/sample - loss: 0.7548 - accuracy: 0.7867\n",
      "Epoch 42/300\n",
      "150/150 [==============================] - 0s 79us/sample - loss: 0.7487 - accuracy: 0.7867\n",
      "Epoch 43/300\n",
      "150/150 [==============================] - 0s 85us/sample - loss: 0.7427 - accuracy: 0.7867\n",
      "Epoch 44/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.7372 - accuracy: 0.7933\n",
      "Epoch 45/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.7315 - accuracy: 0.7933\n",
      "Epoch 46/300\n",
      "150/150 [==============================] - 0s 71us/sample - loss: 0.7260 - accuracy: 0.7933\n",
      "Epoch 47/300\n",
      "150/150 [==============================] - 0s 105us/sample - loss: 0.7207 - accuracy: 0.7933\n",
      "Epoch 48/300\n",
      "150/150 [==============================] - 0s 78us/sample - loss: 0.7154 - accuracy: 0.7933\n",
      "Epoch 49/300\n",
      "150/150 [==============================] - 0s 81us/sample - loss: 0.7102 - accuracy: 0.8000\n",
      "Epoch 50/300\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.7054 - accuracy: 0.7867\n",
      "Epoch 51/300\n",
      "150/150 [==============================] - 0s 71us/sample - loss: 0.7004 - accuracy: 0.7867\n",
      "Epoch 52/300\n",
      "150/150 [==============================] - 0s 79us/sample - loss: 0.6957 - accuracy: 0.7867\n",
      "Epoch 53/300\n",
      "150/150 [==============================] - 0s 94us/sample - loss: 0.6911 - accuracy: 0.7867\n",
      "Epoch 54/300\n",
      "150/150 [==============================] - 0s 65us/sample - loss: 0.6863 - accuracy: 0.7800\n",
      "Epoch 55/300\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.6818 - accuracy: 0.7867\n",
      "Epoch 56/300\n",
      "150/150 [==============================] - 0s 71us/sample - loss: 0.6774 - accuracy: 0.7867\n",
      "Epoch 57/300\n",
      "150/150 [==============================] - 0s 77us/sample - loss: 0.6730 - accuracy: 0.7867\n",
      "Epoch 58/300\n",
      "150/150 [==============================] - 0s 95us/sample - loss: 0.6687 - accuracy: 0.7800\n",
      "Epoch 59/300\n",
      "150/150 [==============================] - 0s 65us/sample - loss: 0.6646 - accuracy: 0.7867\n",
      "Epoch 60/300\n",
      "150/150 [==============================] - 0s 72us/sample - loss: 0.6602 - accuracy: 0.7867\n",
      "Epoch 61/300\n",
      "150/150 [==============================] - 0s 88us/sample - loss: 0.6563 - accuracy: 0.8000\n",
      "Epoch 62/300\n",
      "150/150 [==============================] - 0s 88us/sample - loss: 0.6522 - accuracy: 0.8000\n",
      "Epoch 63/300\n",
      "150/150 [==============================] - 0s 104us/sample - loss: 0.6481 - accuracy: 0.8000\n",
      "Epoch 64/300\n",
      "150/150 [==============================] - 0s 103us/sample - loss: 0.6442 - accuracy: 0.8067\n",
      "Epoch 65/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.6403 - accuracy: 0.7933\n",
      "Epoch 66/300\n",
      "150/150 [==============================] - 0s 109us/sample - loss: 0.6364 - accuracy: 0.8000\n",
      "Epoch 67/300\n",
      "150/150 [==============================] - 0s 77us/sample - loss: 0.6326 - accuracy: 0.8000\n",
      "Epoch 68/300\n",
      "150/150 [==============================] - 0s 95us/sample - loss: 0.6290 - accuracy: 0.7867\n",
      "Epoch 69/300\n",
      "150/150 [==============================] - 0s 216us/sample - loss: 0.6253 - accuracy: 0.7867\n",
      "Epoch 70/300\n",
      "150/150 [==============================] - 0s 174us/sample - loss: 0.6218 - accuracy: 0.7867\n",
      "Epoch 71/300\n",
      "150/150 [==============================] - 0s 161us/sample - loss: 0.6181 - accuracy: 0.7800\n",
      "Epoch 72/300\n",
      "150/150 [==============================] - 0s 95us/sample - loss: 0.6145 - accuracy: 0.7867\n",
      "Epoch 73/300\n",
      "150/150 [==============================] - 0s 102us/sample - loss: 0.6112 - accuracy: 0.7667\n",
      "Epoch 74/300\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.6078 - accuracy: 0.7667\n",
      "Epoch 75/300\n",
      "150/150 [==============================] - 0s 78us/sample - loss: 0.6045 - accuracy: 0.7733\n",
      "Epoch 76/300\n",
      "150/150 [==============================] - 0s 61us/sample - loss: 0.6011 - accuracy: 0.7733\n",
      "Epoch 77/300\n",
      "150/150 [==============================] - 0s 76us/sample - loss: 0.5980 - accuracy: 0.7733\n",
      "Epoch 78/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 59us/sample - loss: 0.5947 - accuracy: 0.7733\n",
      "Epoch 79/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5916 - accuracy: 0.7733\n",
      "Epoch 80/300\n",
      "150/150 [==============================] - 0s 75us/sample - loss: 0.5887 - accuracy: 0.7733\n",
      "Epoch 81/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.5855 - accuracy: 0.7733\n",
      "Epoch 82/300\n",
      "150/150 [==============================] - 0s 82us/sample - loss: 0.5826 - accuracy: 0.7667\n",
      "Epoch 83/300\n",
      "150/150 [==============================] - 0s 75us/sample - loss: 0.5796 - accuracy: 0.7667\n",
      "Epoch 84/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5767 - accuracy: 0.7600\n",
      "Epoch 85/300\n",
      "150/150 [==============================] - 0s 62us/sample - loss: 0.5740 - accuracy: 0.7600\n",
      "Epoch 86/300\n",
      "150/150 [==============================] - 0s 76us/sample - loss: 0.5711 - accuracy: 0.7600\n",
      "Epoch 87/300\n",
      "150/150 [==============================] - 0s 70us/sample - loss: 0.5686 - accuracy: 0.7533\n",
      "Epoch 88/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.5658 - accuracy: 0.7533\n",
      "Epoch 89/300\n",
      "150/150 [==============================] - 0s 74us/sample - loss: 0.5631 - accuracy: 0.7600\n",
      "Epoch 90/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5606 - accuracy: 0.7600\n",
      "Epoch 91/300\n",
      "150/150 [==============================] - 0s 64us/sample - loss: 0.5580 - accuracy: 0.7600\n",
      "Epoch 92/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.5554 - accuracy: 0.7600\n",
      "Epoch 93/300\n",
      "150/150 [==============================] - 0s 70us/sample - loss: 0.5529 - accuracy: 0.7667\n",
      "Epoch 94/300\n",
      "150/150 [==============================] - 0s 61us/sample - loss: 0.5506 - accuracy: 0.7667\n",
      "Epoch 95/300\n",
      "150/150 [==============================] - 0s 63us/sample - loss: 0.5480 - accuracy: 0.7733\n",
      "Epoch 96/300\n",
      "150/150 [==============================] - 0s 69us/sample - loss: 0.5458 - accuracy: 0.7733\n",
      "Epoch 97/300\n",
      "150/150 [==============================] - 0s 64us/sample - loss: 0.5435 - accuracy: 0.7800\n",
      "Epoch 98/300\n",
      "150/150 [==============================] - 0s 71us/sample - loss: 0.5411 - accuracy: 0.7733\n",
      "Epoch 99/300\n",
      "150/150 [==============================] - 0s 77us/sample - loss: 0.5388 - accuracy: 0.7733\n",
      "Epoch 100/300\n",
      "150/150 [==============================] - 0s 78us/sample - loss: 0.5365 - accuracy: 0.7667\n",
      "Epoch 101/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5343 - accuracy: 0.7667\n",
      "Epoch 102/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5321 - accuracy: 0.7667\n",
      "Epoch 103/300\n",
      "150/150 [==============================] - 0s 71us/sample - loss: 0.5300 - accuracy: 0.7667\n",
      "Epoch 104/300\n",
      "150/150 [==============================] - 0s 83us/sample - loss: 0.5279 - accuracy: 0.7667\n",
      "Epoch 105/300\n",
      "150/150 [==============================] - 0s 74us/sample - loss: 0.5258 - accuracy: 0.7667\n",
      "Epoch 106/300\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.5238 - accuracy: 0.7667\n",
      "Epoch 107/300\n",
      "150/150 [==============================] - 0s 75us/sample - loss: 0.5216 - accuracy: 0.7667\n",
      "Epoch 108/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.5197 - accuracy: 0.7667\n",
      "Epoch 109/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.5177 - accuracy: 0.7667\n",
      "Epoch 110/300\n",
      "150/150 [==============================] - 0s 150us/sample - loss: 0.5158 - accuracy: 0.7733\n",
      "Epoch 111/300\n",
      "150/150 [==============================] - 0s 117us/sample - loss: 0.5138 - accuracy: 0.7800\n",
      "Epoch 112/300\n",
      "150/150 [==============================] - 0s 114us/sample - loss: 0.5119 - accuracy: 0.7867\n",
      "Epoch 113/300\n",
      "150/150 [==============================] - 0s 128us/sample - loss: 0.5102 - accuracy: 0.7933\n",
      "Epoch 114/300\n",
      "150/150 [==============================] - 0s 150us/sample - loss: 0.5083 - accuracy: 0.8000\n",
      "Epoch 115/300\n",
      "150/150 [==============================] - 0s 141us/sample - loss: 0.5063 - accuracy: 0.7933\n",
      "Epoch 116/300\n",
      "150/150 [==============================] - 0s 154us/sample - loss: 0.5046 - accuracy: 0.7733\n",
      "Epoch 117/300\n",
      "150/150 [==============================] - 0s 124us/sample - loss: 0.5027 - accuracy: 0.7733\n",
      "Epoch 118/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.5010 - accuracy: 0.7733\n",
      "Epoch 119/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.4992 - accuracy: 0.7800\n",
      "Epoch 120/300\n",
      "150/150 [==============================] - 0s 92us/sample - loss: 0.4975 - accuracy: 0.7933\n",
      "Epoch 121/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.4957 - accuracy: 0.7933\n",
      "Epoch 122/300\n",
      "150/150 [==============================] - 0s 104us/sample - loss: 0.4941 - accuracy: 0.8000\n",
      "Epoch 123/300\n",
      "150/150 [==============================] - 0s 105us/sample - loss: 0.4923 - accuracy: 0.8000\n",
      "Epoch 124/300\n",
      "150/150 [==============================] - 0s 97us/sample - loss: 0.4907 - accuracy: 0.7933\n",
      "Epoch 125/300\n",
      "150/150 [==============================] - 0s 122us/sample - loss: 0.4891 - accuracy: 0.8000\n",
      "Epoch 126/300\n",
      "150/150 [==============================] - 0s 109us/sample - loss: 0.4874 - accuracy: 0.8067\n",
      "Epoch 127/300\n",
      "150/150 [==============================] - 0s 109us/sample - loss: 0.4858 - accuracy: 0.8200\n",
      "Epoch 128/300\n",
      "150/150 [==============================] - 0s 117us/sample - loss: 0.4844 - accuracy: 0.8267\n",
      "Epoch 129/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.4826 - accuracy: 0.8267\n",
      "Epoch 130/300\n",
      "150/150 [==============================] - 0s 112us/sample - loss: 0.4811 - accuracy: 0.8267\n",
      "Epoch 131/300\n",
      "150/150 [==============================] - 0s 110us/sample - loss: 0.4796 - accuracy: 0.8267\n",
      "Epoch 132/300\n",
      "150/150 [==============================] - 0s 112us/sample - loss: 0.4780 - accuracy: 0.8267\n",
      "Epoch 133/300\n",
      "150/150 [==============================] - 0s 122us/sample - loss: 0.4765 - accuracy: 0.8267\n",
      "Epoch 134/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.4750 - accuracy: 0.8267\n",
      "Epoch 135/300\n",
      "150/150 [==============================] - 0s 109us/sample - loss: 0.4734 - accuracy: 0.8267\n",
      "Epoch 136/300\n",
      "150/150 [==============================] - 0s 99us/sample - loss: 0.4720 - accuracy: 0.8267\n",
      "Epoch 137/300\n",
      "150/150 [==============================] - 0s 103us/sample - loss: 0.4706 - accuracy: 0.8333\n",
      "Epoch 138/300\n",
      "150/150 [==============================] - 0s 101us/sample - loss: 0.4690 - accuracy: 0.8467\n",
      "Epoch 139/300\n",
      "150/150 [==============================] - 0s 101us/sample - loss: 0.4676 - accuracy: 0.8600\n",
      "Epoch 140/300\n",
      "150/150 [==============================] - 0s 97us/sample - loss: 0.4663 - accuracy: 0.8600\n",
      "Epoch 141/300\n",
      "150/150 [==============================] - 0s 109us/sample - loss: 0.4647 - accuracy: 0.8600\n",
      "Epoch 142/300\n",
      "150/150 [==============================] - 0s 95us/sample - loss: 0.4633 - accuracy: 0.8467\n",
      "Epoch 143/300\n",
      "150/150 [==============================] - 0s 134us/sample - loss: 0.4620 - accuracy: 0.8533\n",
      "Epoch 144/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.4605 - accuracy: 0.8600\n",
      "Epoch 145/300\n",
      "150/150 [==============================] - 0s 90us/sample - loss: 0.4591 - accuracy: 0.8600\n",
      "Epoch 146/300\n",
      "150/150 [==============================] - 0s 91us/sample - loss: 0.4577 - accuracy: 0.8600\n",
      "Epoch 147/300\n",
      "150/150 [==============================] - 0s 95us/sample - loss: 0.4564 - accuracy: 0.8600\n",
      "Epoch 148/300\n",
      "150/150 [==============================] - 0s 88us/sample - loss: 0.4551 - accuracy: 0.8600\n",
      "Epoch 149/300\n",
      "150/150 [==============================] - 0s 102us/sample - loss: 0.4536 - accuracy: 0.8733\n",
      "Epoch 150/300\n",
      "150/150 [==============================] - 0s 102us/sample - loss: 0.4523 - accuracy: 0.8733\n",
      "Epoch 151/300\n",
      "150/150 [==============================] - 0s 124us/sample - loss: 0.4510 - accuracy: 0.8733\n",
      "Epoch 152/300\n",
      "150/150 [==============================] - 0s 171us/sample - loss: 0.4496 - accuracy: 0.8800\n",
      "Epoch 153/300\n",
      "150/150 [==============================] - 0s 114us/sample - loss: 0.4483 - accuracy: 0.8800\n",
      "Epoch 154/300\n",
      "150/150 [==============================] - 0s 124us/sample - loss: 0.4471 - accuracy: 0.8800\n",
      "Epoch 155/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 120us/sample - loss: 0.4457 - accuracy: 0.8800\n",
      "Epoch 156/300\n",
      "150/150 [==============================] - 0s 179us/sample - loss: 0.4446 - accuracy: 0.8800\n",
      "Epoch 157/300\n",
      "150/150 [==============================] - 0s 237us/sample - loss: 0.4431 - accuracy: 0.8800\n",
      "Epoch 158/300\n",
      "150/150 [==============================] - 0s 124us/sample - loss: 0.4421 - accuracy: 0.8800\n",
      "Epoch 159/300\n",
      "150/150 [==============================] - 0s 114us/sample - loss: 0.4406 - accuracy: 0.8800\n",
      "Epoch 160/300\n",
      "150/150 [==============================] - 0s 141us/sample - loss: 0.4393 - accuracy: 0.8867\n",
      "Epoch 161/300\n",
      "150/150 [==============================] - 0s 123us/sample - loss: 0.4381 - accuracy: 0.8933\n",
      "Epoch 162/300\n",
      "150/150 [==============================] - 0s 170us/sample - loss: 0.4369 - accuracy: 0.8933\n",
      "Epoch 163/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.4355 - accuracy: 0.8933\n",
      "Epoch 164/300\n",
      "150/150 [==============================] - 0s 114us/sample - loss: 0.4343 - accuracy: 0.8933\n",
      "Epoch 165/300\n",
      "150/150 [==============================] - 0s 125us/sample - loss: 0.4332 - accuracy: 0.8933\n",
      "Epoch 166/300\n",
      "150/150 [==============================] - 0s 137us/sample - loss: 0.4318 - accuracy: 0.8933\n",
      "Epoch 167/300\n",
      "150/150 [==============================] - 0s 199us/sample - loss: 0.4306 - accuracy: 0.8933\n",
      "Epoch 168/300\n",
      "150/150 [==============================] - 0s 105us/sample - loss: 0.4294 - accuracy: 0.8933\n",
      "Epoch 169/300\n",
      "150/150 [==============================] - 0s 134us/sample - loss: 0.4282 - accuracy: 0.8933\n",
      "Epoch 170/300\n",
      "150/150 [==============================] - 0s 138us/sample - loss: 0.4269 - accuracy: 0.8933\n",
      "Epoch 171/300\n",
      "150/150 [==============================] - 0s 144us/sample - loss: 0.4257 - accuracy: 0.9000\n",
      "Epoch 172/300\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.4245 - accuracy: 0.9000\n",
      "Epoch 173/300\n",
      "150/150 [==============================] - 0s 149us/sample - loss: 0.4233 - accuracy: 0.9000\n",
      "Epoch 174/300\n",
      "150/150 [==============================] - 0s 105us/sample - loss: 0.4220 - accuracy: 0.9000\n",
      "Epoch 175/300\n",
      "150/150 [==============================] - 0s 84us/sample - loss: 0.4210 - accuracy: 0.8933\n",
      "Epoch 176/300\n",
      "150/150 [==============================] - 0s 99us/sample - loss: 0.4196 - accuracy: 0.8933\n",
      "Epoch 177/300\n",
      "150/150 [==============================] - 0s 102us/sample - loss: 0.4186 - accuracy: 0.8933\n",
      "Epoch 178/300\n",
      "150/150 [==============================] - 0s 152us/sample - loss: 0.4173 - accuracy: 0.9000\n",
      "Epoch 179/300\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.4161 - accuracy: 0.9067\n",
      "Epoch 180/300\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.4319 - accuracy: 0.93 - 0s 153us/sample - loss: 0.4150 - accuracy: 0.9067\n",
      "Epoch 181/300\n",
      "150/150 [==============================] - 0s 168us/sample - loss: 0.4137 - accuracy: 0.9133\n",
      "Epoch 182/300\n",
      "150/150 [==============================] - 0s 153us/sample - loss: 0.4125 - accuracy: 0.9267\n",
      "Epoch 183/300\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.4115 - accuracy: 0.9333\n",
      "Epoch 184/300\n",
      "150/150 [==============================] - 0s 117us/sample - loss: 0.4102 - accuracy: 0.9333\n",
      "Epoch 185/300\n",
      "150/150 [==============================] - 0s 83us/sample - loss: 0.4089 - accuracy: 0.9333\n",
      "Epoch 186/300\n",
      "150/150 [==============================] - 0s 85us/sample - loss: 0.4078 - accuracy: 0.9400\n",
      "Epoch 187/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.4067 - accuracy: 0.9400\n",
      "Epoch 188/300\n",
      "150/150 [==============================] - 0s 76us/sample - loss: 0.4055 - accuracy: 0.9400\n",
      "Epoch 189/300\n",
      "150/150 [==============================] - 0s 91us/sample - loss: 0.4043 - accuracy: 0.9400\n",
      "Epoch 190/300\n",
      "150/150 [==============================] - 0s 111us/sample - loss: 0.4031 - accuracy: 0.9400\n",
      "Epoch 191/300\n",
      "150/150 [==============================] - 0s 92us/sample - loss: 0.4020 - accuracy: 0.9400\n",
      "Epoch 192/300\n",
      "150/150 [==============================] - 0s 85us/sample - loss: 0.4008 - accuracy: 0.9400\n",
      "Epoch 193/300\n",
      "150/150 [==============================] - 0s 69us/sample - loss: 0.3996 - accuracy: 0.9400\n",
      "Epoch 194/300\n",
      "150/150 [==============================] - 0s 82us/sample - loss: 0.3986 - accuracy: 0.9400\n",
      "Epoch 195/300\n",
      "150/150 [==============================] - 0s 95us/sample - loss: 0.3974 - accuracy: 0.9400\n",
      "Epoch 196/300\n",
      "150/150 [==============================] - 0s 85us/sample - loss: 0.3963 - accuracy: 0.9400\n",
      "Epoch 197/300\n",
      "150/150 [==============================] - 0s 95us/sample - loss: 0.3950 - accuracy: 0.9467\n",
      "Epoch 198/300\n",
      "150/150 [==============================] - 0s 91us/sample - loss: 0.3939 - accuracy: 0.9467\n",
      "Epoch 199/300\n",
      "150/150 [==============================] - 0s 70us/sample - loss: 0.3927 - accuracy: 0.9467\n",
      "Epoch 200/300\n",
      "150/150 [==============================] - 0s 69us/sample - loss: 0.3916 - accuracy: 0.9467\n",
      "Epoch 201/300\n",
      "150/150 [==============================] - 0s 85us/sample - loss: 0.3904 - accuracy: 0.9467\n",
      "Epoch 202/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.3895 - accuracy: 0.9400\n",
      "Epoch 203/300\n",
      "150/150 [==============================] - 0s 84us/sample - loss: 0.3881 - accuracy: 0.9467\n",
      "Epoch 204/300\n",
      "150/150 [==============================] - 0s 88us/sample - loss: 0.3869 - accuracy: 0.9467\n",
      "Epoch 205/300\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.3829 - accuracy: 0.93 - 0s 68us/sample - loss: 0.3857 - accuracy: 0.9467\n",
      "Epoch 206/300\n",
      "150/150 [==============================] - 0s 63us/sample - loss: 0.3846 - accuracy: 0.9467\n",
      "Epoch 207/300\n",
      "150/150 [==============================] - 0s 92us/sample - loss: 0.3834 - accuracy: 0.9467\n",
      "Epoch 208/300\n",
      "150/150 [==============================] - 0s 92us/sample - loss: 0.3824 - accuracy: 0.9467\n",
      "Epoch 209/300\n",
      "150/150 [==============================] - 0s 79us/sample - loss: 0.3813 - accuracy: 0.9467\n",
      "Epoch 210/300\n",
      "150/150 [==============================] - 0s 70us/sample - loss: 0.3800 - accuracy: 0.9467\n",
      "Epoch 211/300\n",
      "150/150 [==============================] - 0s 64us/sample - loss: 0.3788 - accuracy: 0.9467\n",
      "Epoch 212/300\n",
      "150/150 [==============================] - 0s 79us/sample - loss: 0.3778 - accuracy: 0.9467\n",
      "Epoch 213/300\n",
      "150/150 [==============================] - 0s 63us/sample - loss: 0.3766 - accuracy: 0.9467\n",
      "Epoch 214/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.3755 - accuracy: 0.9467\n",
      "Epoch 215/300\n",
      "150/150 [==============================] - 0s 70us/sample - loss: 0.3744 - accuracy: 0.9467\n",
      "Epoch 216/300\n",
      "150/150 [==============================] - 0s 75us/sample - loss: 0.3733 - accuracy: 0.9467\n",
      "Epoch 217/300\n",
      "150/150 [==============================] - 0s 57us/sample - loss: 0.3724 - accuracy: 0.9533\n",
      "Epoch 218/300\n",
      "150/150 [==============================] - 0s 78us/sample - loss: 0.3710 - accuracy: 0.9600\n",
      "Epoch 219/300\n",
      "150/150 [==============================] - 0s 76us/sample - loss: 0.3699 - accuracy: 0.9600\n",
      "Epoch 220/300\n",
      "150/150 [==============================] - 0s 83us/sample - loss: 0.3688 - accuracy: 0.9600\n",
      "Epoch 221/300\n",
      "150/150 [==============================] - 0s 79us/sample - loss: 0.3677 - accuracy: 0.9600\n",
      "Epoch 222/300\n",
      "150/150 [==============================] - 0s 62us/sample - loss: 0.3665 - accuracy: 0.9600\n",
      "Epoch 223/300\n",
      "150/150 [==============================] - 0s 81us/sample - loss: 0.3654 - accuracy: 0.9600\n",
      "Epoch 224/300\n",
      "150/150 [==============================] - 0s 72us/sample - loss: 0.3643 - accuracy: 0.9533\n",
      "Epoch 225/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.3632 - accuracy: 0.9667\n",
      "Epoch 226/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3622 - accuracy: 0.9600\n",
      "Epoch 227/300\n",
      "150/150 [==============================] - 0s 114us/sample - loss: 0.3610 - accuracy: 0.9667\n",
      "Epoch 228/300\n",
      "150/150 [==============================] - 0s 104us/sample - loss: 0.3599 - accuracy: 0.9667\n",
      "Epoch 229/300\n",
      "150/150 [==============================] - 0s 83us/sample - loss: 0.3587 - accuracy: 0.9667\n",
      "Epoch 230/300\n",
      "150/150 [==============================] - 0s 59us/sample - loss: 0.3576 - accuracy: 0.9667\n",
      "Epoch 231/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 66us/sample - loss: 0.3564 - accuracy: 0.9667\n",
      "Epoch 232/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.3554 - accuracy: 0.9667\n",
      "Epoch 233/300\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.3543 - accuracy: 0.9667\n",
      "Epoch 234/300\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.3531 - accuracy: 0.9667\n",
      "Epoch 235/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.3520 - accuracy: 0.9667\n",
      "Epoch 236/300\n",
      "150/150 [==============================] - 0s 99us/sample - loss: 0.3509 - accuracy: 0.9667\n",
      "Epoch 237/300\n",
      "150/150 [==============================] - 0s 125us/sample - loss: 0.3501 - accuracy: 0.9733\n",
      "Epoch 238/300\n",
      "150/150 [==============================] - 0s 76us/sample - loss: 0.3487 - accuracy: 0.9733\n",
      "Epoch 239/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.3476 - accuracy: 0.9667\n",
      "Epoch 240/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.3466 - accuracy: 0.9667\n",
      "Epoch 241/300\n",
      "150/150 [==============================] - 0s 85us/sample - loss: 0.3454 - accuracy: 0.9667\n",
      "Epoch 242/300\n",
      "150/150 [==============================] - 0s 101us/sample - loss: 0.3446 - accuracy: 0.9667\n",
      "Epoch 243/300\n",
      "150/150 [==============================] - 0s 90us/sample - loss: 0.3431 - accuracy: 0.9667\n",
      "Epoch 244/300\n",
      "150/150 [==============================] - 0s 136us/sample - loss: 0.3422 - accuracy: 0.9667\n",
      "Epoch 245/300\n",
      "150/150 [==============================] - 0s 108us/sample - loss: 0.3410 - accuracy: 0.9733\n",
      "Epoch 246/300\n",
      "150/150 [==============================] - 0s 119us/sample - loss: 0.3400 - accuracy: 0.9733\n",
      "Epoch 247/300\n",
      "150/150 [==============================] - 0s 110us/sample - loss: 0.3392 - accuracy: 0.9733\n",
      "Epoch 248/300\n",
      "150/150 [==============================] - 0s 131us/sample - loss: 0.3378 - accuracy: 0.9733\n",
      "Epoch 249/300\n",
      "150/150 [==============================] - 0s 103us/sample - loss: 0.3367 - accuracy: 0.9667\n",
      "Epoch 250/300\n",
      "150/150 [==============================] - 0s 101us/sample - loss: 0.3356 - accuracy: 0.9667\n",
      "Epoch 251/300\n",
      "150/150 [==============================] - 0s 101us/sample - loss: 0.3346 - accuracy: 0.9667\n",
      "Epoch 252/300\n",
      "150/150 [==============================] - 0s 144us/sample - loss: 0.3334 - accuracy: 0.9667\n",
      "Epoch 253/300\n",
      "150/150 [==============================] - 0s 141us/sample - loss: 0.3325 - accuracy: 0.9667\n",
      "Epoch 254/300\n",
      "150/150 [==============================] - 0s 161us/sample - loss: 0.3315 - accuracy: 0.9667\n",
      "Epoch 255/300\n",
      "150/150 [==============================] - 0s 194us/sample - loss: 0.3302 - accuracy: 0.9667\n",
      "Epoch 256/300\n",
      "150/150 [==============================] - 0s 157us/sample - loss: 0.3292 - accuracy: 0.9667\n",
      "Epoch 257/300\n",
      "150/150 [==============================] - 0s 147us/sample - loss: 0.3281 - accuracy: 0.9667\n",
      "Epoch 258/300\n",
      "150/150 [==============================] - 0s 125us/sample - loss: 0.3271 - accuracy: 0.9667\n",
      "Epoch 259/300\n",
      "150/150 [==============================] - 0s 123us/sample - loss: 0.3261 - accuracy: 0.9667\n",
      "Epoch 260/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.3250 - accuracy: 0.9667\n",
      "Epoch 261/300\n",
      "150/150 [==============================] - 0s 62us/sample - loss: 0.3240 - accuracy: 0.9667\n",
      "Epoch 262/300\n",
      "150/150 [==============================] - 0s 83us/sample - loss: 0.3229 - accuracy: 0.9667\n",
      "Epoch 263/300\n",
      "150/150 [==============================] - 0s 82us/sample - loss: 0.3219 - accuracy: 0.9667\n",
      "Epoch 264/300\n",
      "150/150 [==============================] - 0s 69us/sample - loss: 0.3209 - accuracy: 0.9667\n",
      "Epoch 265/300\n",
      "150/150 [==============================] - 0s 81us/sample - loss: 0.3197 - accuracy: 0.9667\n",
      "Epoch 266/300\n",
      "150/150 [==============================] - 0s 74us/sample - loss: 0.3188 - accuracy: 0.9667\n",
      "Epoch 267/300\n",
      "150/150 [==============================] - 0s 75us/sample - loss: 0.3177 - accuracy: 0.9667\n",
      "Epoch 268/300\n",
      "150/150 [==============================] - 0s 81us/sample - loss: 0.3168 - accuracy: 0.9667\n",
      "Epoch 269/300\n",
      "150/150 [==============================] - 0s 63us/sample - loss: 0.3157 - accuracy: 0.9667\n",
      "Epoch 270/300\n",
      "150/150 [==============================] - 0s 85us/sample - loss: 0.3146 - accuracy: 0.9667\n",
      "Epoch 271/300\n",
      "150/150 [==============================] - 0s 90us/sample - loss: 0.3135 - accuracy: 0.9667\n",
      "Epoch 272/300\n",
      "150/150 [==============================] - 0s 77us/sample - loss: 0.3125 - accuracy: 0.9667\n",
      "Epoch 273/300\n",
      "150/150 [==============================] - 0s 62us/sample - loss: 0.3115 - accuracy: 0.9667\n",
      "Epoch 274/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.3105 - accuracy: 0.9667\n",
      "Epoch 275/300\n",
      "150/150 [==============================] - 0s 89us/sample - loss: 0.3095 - accuracy: 0.9667\n",
      "Epoch 276/300\n",
      "150/150 [==============================] - 0s 85us/sample - loss: 0.3085 - accuracy: 0.9667\n",
      "Epoch 277/300\n",
      "150/150 [==============================] - 0s 62us/sample - loss: 0.3076 - accuracy: 0.9667\n",
      "Epoch 278/300\n",
      "150/150 [==============================] - 0s 81us/sample - loss: 0.3067 - accuracy: 0.9667\n",
      "Epoch 279/300\n",
      "150/150 [==============================] - 0s 76us/sample - loss: 0.3055 - accuracy: 0.9667\n",
      "Epoch 280/300\n",
      "150/150 [==============================] - 0s 77us/sample - loss: 0.3046 - accuracy: 0.9667\n",
      "Epoch 281/300\n",
      "150/150 [==============================] - 0s 64us/sample - loss: 0.3036 - accuracy: 0.9667\n",
      "Epoch 282/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.3025 - accuracy: 0.9667\n",
      "Epoch 283/300\n",
      "150/150 [==============================] - 0s 79us/sample - loss: 0.3016 - accuracy: 0.9667\n",
      "Epoch 284/300\n",
      "150/150 [==============================] - 0s 76us/sample - loss: 0.3006 - accuracy: 0.9667\n",
      "Epoch 285/300\n",
      "150/150 [==============================] - 0s 71us/sample - loss: 0.2997 - accuracy: 0.9667\n",
      "Epoch 286/300\n",
      "150/150 [==============================] - 0s 76us/sample - loss: 0.2985 - accuracy: 0.9667\n",
      "Epoch 287/300\n",
      "150/150 [==============================] - 0s 77us/sample - loss: 0.2977 - accuracy: 0.9667\n",
      "Epoch 288/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.2966 - accuracy: 0.9667\n",
      "Epoch 289/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.2959 - accuracy: 0.9667\n",
      "Epoch 290/300\n",
      "150/150 [==============================] - 0s 75us/sample - loss: 0.2948 - accuracy: 0.9667\n",
      "Epoch 291/300\n",
      "150/150 [==============================] - 0s 76us/sample - loss: 0.2939 - accuracy: 0.9667\n",
      "Epoch 292/300\n",
      "150/150 [==============================] - 0s 84us/sample - loss: 0.2932 - accuracy: 0.9667\n",
      "Epoch 293/300\n",
      "150/150 [==============================] - 0s 81us/sample - loss: 0.2919 - accuracy: 0.9667\n",
      "Epoch 294/300\n",
      "150/150 [==============================] - 0s 63us/sample - loss: 0.2909 - accuracy: 0.9667\n",
      "Epoch 295/300\n",
      "150/150 [==============================] - 0s 90us/sample - loss: 0.2900 - accuracy: 0.9667\n",
      "Epoch 296/300\n",
      "150/150 [==============================] - 0s 82us/sample - loss: 0.2891 - accuracy: 0.9667\n",
      "Epoch 297/300\n",
      "150/150 [==============================] - 0s 94us/sample - loss: 0.2881 - accuracy: 0.9667\n",
      "Epoch 298/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2872 - accuracy: 0.9667\n",
      "Epoch 299/300\n",
      "150/150 [==============================] - 0s 88us/sample - loss: 0.2863 - accuracy: 0.9667\n",
      "Epoch 300/300\n",
      "150/150 [==============================] - 0s 76us/sample - loss: 0.2853 - accuracy: 0.9667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1494547b8>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X_complete, y, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('../model', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../model/iris_classification_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../model/iris_classification_scaler.pkl']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler, '../model/iris_classification_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_model = load_model('../model/iris_classification_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_scaler = joblib.load('../model/iris_classification_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_example = {\n",
    "    \"sepal_length\": 5.1,\n",
    "    \"sepal_width\": 3.5,\n",
    "    \"petal_length\": 1.4,\n",
    "    \"petal_width\": 0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_prediction(model, scaler, sample_json):\n",
    "    sepal_length = sample_json['sepal_length']\n",
    "    sepal_width = sample_json['sepal_width']\n",
    "    petal_length = sample_json['petal_length']\n",
    "    petal_width = sample_json['petal_width']\n",
    "    classes = np.array(['setosa', 'versicolor', 'virginica'])\n",
    "    flower = [[sepal_length, sepal_width, petal_length, petal_width]]\n",
    "    flower = scaler.transform(flower)\n",
    "    class_index = model.predict_classes(flower)\n",
    "    return classes[class_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa'], dtype='<U10')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_prediction(flower_model, flower_scaler, flower_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
